<!doctype html>
<html lang="en">
<head>
<title>anatomies_of_intelligence</title>
<meta name="generator" content="Etherpad">
<meta name="author" content="Etherpad">
<meta name="changedby" content="Etherpad">
<meta charset="utf-8">
<style>
* {
  font-family: arial, sans-serif;
  font-size: 13px;
  line-height: 17px;
}
ul.indent {
  list-style-type: none;
}
ol {
  list-style-type: none;
  padding-left: 0;
}
body > ol {
  counter-reset: first second third fourth fifth sixth seventh eighth ninth tenth eleventh twelfth thirteenth fourteenth fifteenth sixteenth;
}
ol > li:before {
  content: counter(first) ". ";
  counter-increment: first;
}
ol > ol > li:before {
  content: counter(first) "." counter(second) ". ";
  counter-increment: second;
}
ol > ol > ol > li:before {
  content: counter(first) "." counter(second) "." counter(third) ". ";
  counter-increment: third;
}
ol > ol > ol > ol > li:before {
  content: counter(first) "." counter(second) "." counter(third) "." counter(fourth) ". ";
  counter-increment: fourth;
}
ol > ol > ol > ol > ol > li:before {
  content: counter(first) "." counter(second) "." counter(third) "." counter(fourth) "." counter(fifth) ". ";
  counter-increment: fifth;
}
ol > ol > ol > ol > ol > ol > li:before {
  content: counter(first) "." counter(second) "." counter(third) "." counter(fourth) "." counter(fifth) "." counter(sixth) ". ";
  counter-increment: sixth;
}
ol > ol > ol > ol > ol > ol > ol > li:before {
  content: counter(first) "." counter(second) "." counter(third) "." counter(fourth) "." counter(fifth) "." counter(sixth) "." counter(seventh) ". ";
  counter-increment: seventh;
}
ol > ol > ol > ol > ol > ol > ol > ol > li:before {
  content: counter(first) "." counter(second) "." counter(third) "." counter(fourth) "." counter(fifth) "." counter(sixth) "." counter(seventh) "." counter(eighth) ". ";
  counter-increment: eighth;
}
ol > ol > ol > ol > ol > ol > ol > ol > ol > li:before {
  content: counter(first) "." counter(second) "." counter(third) "." counter(fourth) "." counter(fifth) "." counter(sixth) "." counter(seventh) "." counter(eighth) "." counter(ninth) ". ";
  counter-increment: ninth;
}
ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > li:before {
  content: counter(first) "." counter(second) "." counter(third) "." counter(fourth) "." counter(fifth) "." counter(sixth) "." counter(seventh) "." counter(eighth) "." counter(ninth) "." counter(tenth) ". ";
  counter-increment: tenth;
}
ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > li:before {
  content: counter(first) "." counter(second) "." counter(third) "." counter(fourth) "." counter(fifth) "." counter(sixth) "." counter(seventh) "." counter(eighth) "." counter(ninth) "." counter(tenth) "." counter(eleventh) ". ";
  counter-increment: eleventh;
}
ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > li:before {
  content: counter(first) "." counter(second) "." counter(third) "." counter(fourth) "." counter(fifth) "." counter(sixth) "." counter(seventh) "." counter(eighth) "." counter(ninth) "." counter(tenth) "." counter(eleventh) "." counter(twelfth) ". ";
  counter-increment: twelfth;
}
ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > li:before {
  content: counter(first) "." counter(second) "." counter(third) "." counter(fourth) "." counter(fifth) "." counter(sixth) "." counter(seventh) "." counter(eighth) "." counter(ninth) "." counter(tenth) "." counter(eleventh) "." counter(twelfth) "." counter(thirteenth) ". ";
  counter-increment: thirteenth;
}
ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > li:before {
  content: counter(first) "." counter(second) "." counter(third) "." counter(fourth) "." counter(fifth) "." counter(sixth) "." counter(seventh) "." counter(eighth) "." counter(ninth) "." counter(tenth) "." counter(eleventh) "." counter(twelfth) "." counter(thirteenth) "." counter(fourteenth) ". ";
  counter-increment: fourteenth;
}
ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > li:before {
  content: counter(first) "." counter(second) "." counter(third) "." counter(fourth) "." counter(fifth) "." counter(sixth) "." counter(seventh) "." counter(eighth) "." counter(ninth) "." counter(tenth) "." counter(eleventh) "." counter(twelfth) "." counter(thirteenth) "." counter(fourteenth) "." counter(fifteenth) ". ";
  counter-increment: fifteenth;
}
ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > li:before {
  content: counter(first) "." counter(second) "." counter(third) "." counter(fourth) "." counter(fifth) "." counter(sixth) "." counter(seventh) "." counter(eighth) "." counter(ninth) "." counter(tenth) "." counter(eleventh) "." counter(twelfth) "." counter(thirteenth) "." counter(fourteenth) "." counter(fifteenth) "." counter(sixteenth) ". ";
  counter-increment: sixteenth;
}
ol {
  text-indent: 0px;
}
ol > ol {
  text-indent: 10px;
}
ol > ol > ol {
  text-indent: 20px;
}
ol > ol > ol > ol {
  text-indent: 30px;
}
ol > ol > ol > ol > ol {
  text-indent: 40px;
}
ol > ol > ol > ol > ol > ol {
  text-indent: 50px;
}
ol > ol > ol > ol > ol > ol > ol {
  text-indent: 60px;
}
ol > ol > ol > ol > ol > ol > ol > ol {
  text-indent: 70px;
}
ol > ol > ol > ol > ol > ol > ol > ol > ol {
  text-indent: 80px;
}
ol > ol > ol > ol > ol > ol > ol > ol > ol > ol {
  text-indent: 90px;
}
ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > ol {
  text-indent: 100px;
}
ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > ol {
  text-indent: 110px;
}
ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > ol {
  text-indent: 120px;
}
ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > ol {
  text-indent: 130px;
}
ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > ol {
  text-indent: 140px;
}
ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > ol > ol {
  text-indent: 150px;
}

</style>
</head>
<body>
March 31<br><a href="https&#x3a;&#x2F;&#x2F;soundslikefest&#x2e;com&#x2F;call&#x2d;for&#x2d;artists&#x2d;2020">https:&#x2F;&#x2F;soundslikefest.com&#x2F;call-for-artists-2020</a> &#8212; &gt; applied<br><br><s>4S&#x2F;EASST Prague Algocracy:</s><br><a href="https&#x3a;&#x2F;&#x2F;www&#x2e;algocracy&#x2e;news&#x2F;4s&#x2d;easst&#x2d;prague"><s>https:&#x2F;&#x2F;www.algocracy.news&#x2F;4s-easst-prague</s></a><br><br><s>Funded Residency on Deepfakes:</s><br><a href="https&#x3a;&#x2F;&#x2F;thoughtworksarts&#x2e;io&#x2F;open&#x2d;call&#x2F;2020&#x2d;synthetic&#x2d;media&#x2F;"><s>https:&#x2F;&#x2F;thoughtworksarts.io&#x2F;open-call&#x2F;2020-synthetic-media&#x2F;</s></a><br><br>SUBMISSION DEADLINE: April 10, 2020<br><a href="https&#x3a;&#x2F;&#x2F;www&#x2e;onassis&#x2e;org&#x2F;open&#x2d;calls&#x2F;future&#x2d;now">https:&#x2F;&#x2F;www.onassis.org&#x2F;open-calls&#x2F;future-now</a><br><br><s>Looking for artworks, workshops, and provocations (Bristol)</s><br><a href="https&#x3a;&#x2F;&#x2F;www&#x2e;control&#x2d;shift&#x2e;network&#x2F;call&#x2F;index&#x2e;html"><s>https:&#x2F;&#x2F;www.control-shift.network&#x2F;call&#x2F;index.html</s></a><s> </s>&#8212; &gt; applied<br><br>3rd Workshop on obfuscation<br>post-poned<br>Delft University of Technology<br><a href="http&#x3a;&#x2F;&#x2F;www&#x2e;obfuscationworkshop&#x2e;org&#x2F;">http:&#x2F;&#x2F;www.obfuscationworkshop.org&#x2F;</a><br><br>30 April&nbsp;<br><a href="https&#x3a;&#x2F;&#x2F;zkm&#x2e;de&#x2F;en&#x2F;open&#x2d;call&#x2d;beyond&#x2d;matter&#x2d;residency">https:&#x2F;&#x2F;zkm.de&#x2F;en&#x2F;open-call-beyond-matter-residency</a><br><a href="https&#x3a;&#x2F;&#x2F;www&#x2e;adk&#x2e;de&#x2F;en&#x2F;academy&#x2F;young&#x2d;academy&#x2F;open&#x2d;call&#x2e;htm">https:&#x2F;&#x2F;www.adk.de&#x2F;en&#x2F;academy&#x2F;young-academy&#x2F;open-call.htm</a><br><br>May 7<br><a href="https&#x3a;&#x2F;&#x2F;networkmusicfestival&#x2e;org&#x2F;open&#x2d;call&#x2F;">https:&#x2F;&#x2F;networkmusicfestival.org&#x2F;open-call&#x2F;</a><br><br><br><strong>ideas to connect with V2:</strong><br>&#8212; shorter term&#x2F; explore aesthetic possibilties:<br><ul class="indent"><li>- use of multiple projections;<ul class="indent"><li>- accumulation of iteration &#x27;windows&#x27; on a projection (can work for long performances &#x2F; walk in)&nbsp;</li><li>- different data representations in the browser window(s),&nbsp;</li><li>- spatiality&#x2F;invasiveness of sound,&nbsp;</li><li>- alternative audience-performers set ups...</ul></li></ul>&#8212; long term: hybrid publishing &#8212; &gt; an excuse for interviews with various practioners;<br><ul class="indent"><li>- interviewing practitioners&nbsp;<ul class="indent"><li>- on topics of anatomic collections and dissection&#x2F;preparation techniques;&nbsp;<ul class="indent"><li>- return to Marieke;</ul><li>- data scientists on how these approaches overlap conceptually and practically (in the case of digital anatomical analysis and collection).&nbsp;</ul><li>- print or hybrid publication of our research catalog could function in a way that can be both a tool for experimenting with knowledge-making algorithms as well as a hub for the research content.</ul>possible partners:<br>&nbsp;&nbsp;&nbsp; - welcome collection;<br><br><u>MAY 24 NL_CL#2: FLESH SCHEDULE</u><br>(official announcement says event runs from 20:00-22:30)<br>20:00 &#8212; intro<br>20:10 &#8212; 20:30: Naoto;<br>[tbc 5 min intermezzo Maya&#x27;s score]<br>20:35 &#8212; 21:00: Jon and Joana;<br>[tbc 5 min intermezzo Maya&#x27;s score]<br>21:05 &#8212; 21:30: Angeliki;<br>21:30 &#8212; 22:00 : Q&amp;A;<br><br>* <a href="https&#x3a;&#x2F;&#x2F;instrumentinventors&#x2e;org&#x2F;production&#x2F;diy&#x2d;scores&#x2F;">https:&#x2F;&#x2F;instrumentinventors.org&#x2F;production&#x2F;diy-scores&#x2F;</a>&nbsp;<br><br>Concert Budget<br>&#8364;250: Naoto fee<br>&#8364;250: Angeliki fee<br>&#8364;150: Jon fee<br>&#8364;150: Joana fee<br><br>&#8364;130: Pieter Kiers, photographer<br>&#8364;100: Tech support;&nbsp;<br>: Marije as host?<br>: Maya scores in intermezzo<br>: we pay ourselves a more fair fee &#x2F; could be used later as own contribution to documentation<br><br>Residency Budget<br>- 35 eur per day x two weeks (14 days) = 490 eur &#8212; Joana<br>- production budget of &#8364;500 &#8212; Jonathan<br>: ? 600eu STROOM Documentation Grant <a href="https&#x3a;&#x2F;&#x2F;www&#x2e;stroom&#x2e;nl&#x2F;paginas&#x2F;pagina&#x2e;php&#x3f;pa&#x5f;id&#x3d;3407298">https:&#x2F;&#x2F;www.stroom.nl&#x2F;paginas&#x2F;pagina.php?pa_id=3407298</a><br>- <a href="https&#x3a;&#x2F;&#x2F;www&#x2e;stroom&#x2e;nl&#x2F;media&#x2F;SPOT&#x5f;Documentatie&#x5f;2020&#x5f;Aanvraag&#x5f;Digitaal&#x2e;pdf">https:&#x2F;&#x2F;www.stroom.nl&#x2F;media&#x2F;SPOT_Documentatie_2020_Aanvraag_Digitaal.pdf</a><br>Videographer: <a href="https&#x3a;&#x2F;&#x2F;www&#x2e;tanjabusking&#x2e;nl&#x2F;"><u>https:&#x2F;&#x2F;www.tanjabusking.nl&#x2F;</u></a><br><br><strong><em><u>CONCERT BUDGET</u></em></strong><br><br><strong><em>Artist Fees &#x2F; Travel</em></strong><br>total artist fees in original budget: 1020<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ORIGINAL&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; REDISTRIBUTED (POST-COVID19)<br>Naoto travel&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &#8364;100.00&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &#8364;0.00<br>Naoto fee&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &#8364;250.00&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &#8364;250.00<br>Angeliki travel&nbsp;&nbsp;&nbsp; &#8364;20.00&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &#8364;0.00<br>Angeliki fee&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &#8364;250.00&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &#8364;250.00<br>Jonathan&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &#8364;200.00&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &#8364;250.00<br>Joana&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &#8364;200.00&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &#8364;250.00<br><br><strong><em>total artist fees&#x2F;travel&nbsp; </em></strong>&#8364;1,020.00&nbsp;&nbsp;&nbsp; &#8364;1,000.00<br><br><strong><em>Other Expenses</em></strong><br>Guest Curator Fee Joana&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &#8364;150.00&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &#8364;150.00<br>Guest Host Fee Marije&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &#8364;0.00&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &#8364;150.00&nbsp;&nbsp; Marije brought in as guest host &#x2F; or to Jon&#x2F;Joana for hosting ?<br>Project Management Fee&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &#8364;75.00&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &#8364;115.00&nbsp;&nbsp; Jon organization &#x2F; project management (increased a bit to be more fair)<br>Stage Management &amp; Sound&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &#8364;100.00&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &#8364;100.00&nbsp;&nbsp; redirected to either Joana&#x2F;Joanathan or Marije - depending on who runs &amp; tests streaming system<br>Bar &amp; Door&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &#8364;60.00&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &#8364;0.00&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>Documentation&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &#8364;130.00&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &#8364;0.00&nbsp;&nbsp;&nbsp; redirected to artist fees &#x2F; surplus (to be discussed with Marije)<br><br><strong><em>total other expenses&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </em></strong>&#8364;515.00&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &#8364;515.00<br><strong><em>TOTAL NL_CL #2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </em></strong>&#8364;1,535.00&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &#8364;1,515.00<br><br><br>________________________________________________________<br><strong>iii RESIDENCY &amp; NEW PERFORMANCE</strong><br><br><strong><em>20-26 APR RESIDENCY &#x2F; WORK PERIOD</em></strong><br><strong><em>7-10 MAY DA Z Festival Zurich</em></strong><br><strong><em>18-26th May &#x2F; WORK PERIOD</em></strong><br><strong><em>24 MAY NL_CL CONCERT iii</em></strong><br><br>- aesthetics;<br>- structure; file formating;...<br><br># explorations &amp; goals<br>Create a compelling performance for a wider audience and create compelling documentation of this performance.<br><br><br><strong>(1)</strong> &#8212; April priorities<br>* visual setup, projecting on multiple screens<br><br>performance May framework &#x2F; slowing down:<br>--- one act = only one cluster;&nbsp;<br><ul class="indent"><li><ul class="indent"><li>--- slow clustering:</li><li>--- more detailed sound;</li><li>--- give algorithms a more visceral aesthetic presence (visceral: invasive of the body, alien&#x2F;outside)</ul></li></ul><br>+ inspiration:<br><br>&#8212; on voice:<br>&nbsp;&nbsp;&nbsp; &#8212; Welcome&#8217;s collection on anatomy and voice: <a href="https&#x3a;&#x2F;&#x2F;wellcomecollection&#x2e;org&#x2F;works&#x3f;query&#x3d;voice&amp;search&#x3d;images">https:&#x2F;&#x2F;wellcomecollection.org&#x2F;works?query=voice&amp;search=images</a>&nbsp;<br>&nbsp;&nbsp;&nbsp; - Voice and Code text by Josephine Bosma: <a href="http&#x3a;&#x2F;&#x2F;www&#x2e;josephinebosma&#x2e;com&#x2F;web&#x2F;node&#x2F;4">http:&#x2F;&#x2F;www.josephinebosma.com&#x2F;web&#x2F;node&#x2F;4</a><br>&nbsp;&nbsp;&nbsp; - Voice Heidi Fast and Milla Tiainen <a href="https&#x3a;&#x2F;&#x2F;newmaterialism&#x2e;eu&#x2F;almanac&#x2F;v&#x2F;voice&#x2e;html">https:&#x2F;&#x2F;newmaterialism.eu&#x2F;almanac&#x2F;v&#x2F;voice.html</a><br><ul class="indent"><li>&nbsp;&nbsp;&nbsp; &#8212; Voices also unfold in co-constitutive relations with discourses and social practices that direct, valorize, and mold ways of producing voice. Indeed, voices provide an apt example of what Karen Barad has famously termed <em>intra-action,</em> referring to the ways in which agencies and phenomena do not precede, but rather emerge through their mutual relations (Barad, 2007, p. 33). Voices, themselves, result from intra-actions among corporeality, sounds, technologies, particular cultural techniques, practices of vocalizing, and so forth.</li><li>&nbsp;&nbsp;&nbsp; - Stacy Alaimo&#x27;s (2008) trans-corporeality or Jane Bennett&#x27;s (2010) thing-power and agency of assemblages-- encourage one to locate voice &quot;within a broader nexus of relations between organic and synthetic bodies, actors, and forces&quot; (Thompson and Tiainen, 2017, p. 382).</ul>- visceral&#x2F;invasive aesthetics:&nbsp;<br><ul class="indent"><li><ul class="indent"><li>&nbsp;&nbsp;&nbsp;&nbsp; <a href="https&#x3a;&#x2F;&#x2F;arkdes&#x2e;se&#x2F;en&#x2F;utstallning&#x2F;asmr&#x2d;weird&#x2d;sensation&#x2d;feels&#x2d;good&#x2F;">https:&#x2F;&#x2F;arkdes.se&#x2F;en&#x2F;utstallning&#x2F;asmr-weird-sensation-feels-good&#x2F;</a><ul class="indent"><li><ul class="indent"><li><a href="https&#x3a;&#x2F;&#x2F;www&#x2e;e&#x2d;flux&#x2e;com&#x2F;video&#x2F;325072&#x2F;arkdes&#x2d;nbsp&#x2d;presents&#x2d;a&#x2d;virtual&#x2d;vernissage&#x2d;weird&#x2d;sensation&#x2d;feels&#x2d;good&#x2F;">https:&#x2F;&#x2F;www.e-flux.com&#x2F;video&#x2F;325072&#x2F;arkdes-nbsp-presents-a-virtual-vernissage-weird-sensation-feels-good&#x2F;</a></ul></li></ul><li>- &#x27;Cyberflesh Girlmonster&#x27; by Linda Dement: <a href="https&#x3a;&#x2F;&#x2F;www&#x2e;youtube&#x2e;com&#x2F;watch&#x3f;v&#x3d;uQpRe1B0rJ4">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=uQpRe1B0rJ4</a></li><li>- Links on anatomy: <a href="https&#x3a;&#x2F;&#x2F;hackingwithcare&#x2e;in&#x2F;wiki&#x2F;doku&#x2e;php&#x2F;anatomy">https:&#x2F;&#x2F;hackingwithcare.in&#x2F;wiki&#x2F;doku.php&#x2F;anatomy</a> (? new material for the catalogue)</li><li></ul></li></ul>For publishing exmamples, check: <a href="https&#x3a;&#x2F;&#x2F;github&#x2e;com&#x2F;orgs&#x2F;anatomiesofintelligence&#x2F;projects&#x2F;1">https:&#x2F;&#x2F;github.com&#x2F;orgs&#x2F;anatomiesofintelligence&#x2F;projects&#x2F;1</a><br><br><strong><em><u>20 mon____________________</u></em></strong><br>- planning;<br>- virtual dinner iii (18h);<br><br><strong><em><u>21 tue____________________</u></em></strong><br>- spreadsheet morning &#8212;<br><ul class="indent"><li>- generate spreadsheet &amp; thumbnails via python script</li><li>- call: for discussing vocabulary;</ul>- image thumbnails;<br>&#8212; email: _V2;<br>&#8212; visual experiments;<br><br><strong><em><u>22 wed____________________</u></em></strong><br>- spreadsheet morning &#8212;<br><a href="https&#x3a;&#x2F;&#x2F;docs&#x2e;google&#x2e;com&#x2F;spreadsheets&#x2F;d&#x2F;1H&#x2d;DFzYcQ3NuphQB5bjESzefx1&#x2d;&#x2d;G4D6sZ6y&#x2d;orpfRX4&#x2F;edit&#x3f;userstoinvite&#x3d;reusjc&#x40;gmail&#x2e;com&amp;ts&#x3d;5ea00b5c&amp;actionButton&#x3d;1&#x23;gid&#x3d;884186592">https:&#x2F;&#x2F;docs.google.com&#x2F;spreadsheets&#x2F;d&#x2F;1H-DFzYcQ3NuphQB5bjESzefx1--G4D6sZ6y-orpfRX4&#x2F;edit?userstoinvite=reusjc@gmail.com&amp;ts=5ea00b5c&amp;actionButton=1#gid=884186592</a><br><ul class="indent"><li>- revise vocabulary:<ul class="indent"><li>- how to generalize? granularization;</li><li>- eg. cases: chinese medicine vs oriental</li><li>- describe tags: continuous features vs discrete features&nbsp;<ul class="indent"><li>&#8212; classes (ontological class or soft classes): in blue</li><li>&#8212; intensities (fluid): in yellow</ul><li>&#8212; new classes: probability; analytical; synthetic;</ul><li></ul>&#8212; slow clustering iteration session &#8212;<br><ul class="indent"><li>- make notes on how vocubulary + sound + visuals may come together;</ul><br>- carry on with visual and sound experiments;<br><br><strong><em><u>23 thu____________________</u></em></strong><br>(Jon busy 10:00-13:00)<br>(Joana busy 11h30 &#8212; 13h and 15h-16h)<br>we meet 14h<br><br>- carry on visual and sound experiments;<br><br>- from the experiments, what to implement?<br><br><strong><em><u>24 fri____________________</u></em></strong><br>(Jon busy until 16:00)<br><br>Make decisions on &#8212; iii NL_CL;<br><br>LiveCoding MeetUp (18h30-21)<br><br>- implementing<br><br><strong><em><u>25 sat____________________</u></em></strong><br><br>- implementing<br><br><strong><em><u>26 sun____________________</u></em></strong><br><br>- wrap up; set goals for next residency period;<br><br>* remember to share screenshots &#x2F; process with iii!<br>we can share references;&nbsp;<br>another option is to write a research post;<br>____________________________________________________________________________________________<br><br><strong>(1) visual aspects</strong><br><ul class="indent"><li><strong>(1)</strong> animated&#x2F;visualize clustering process &#x2F; also live reporting (voice) of clustering;<ul class="indent"><li><strong>(1)</strong> expressing clustering:<ul class="indent"><li>- layering of information;</li><li>- size changing dinamically;</li><li>- rotate &#x27;body&#x27;? <a href="https&#x3a;&#x2F;&#x2F;evasive&#x2e;tech&#x2F;5&#x2F;">https:&#x2F;&#x2F;evasive.tech&#x2F;5&#x2F;</a> (like camera view)</li><li>- zoom into entries: <a href="https&#x3a;&#x2F;&#x2F;evasive&#x2e;tech&#x2F;4&#x2F;">https:&#x2F;&#x2F;evasive.tech&#x2F;4&#x2F;</a><ul class="indent"><li><ul class="indent"><li>- see ref:<ul class="indent"><li>+ <a href="https&#x3a;&#x2F;&#x2F;distill&#x2e;pub&#x2F;2016&#x2F;misread&#x2d;tsne&#x2F;">https:&#x2F;&#x2F;distill.pub&#x2F;2016&#x2F;misread-tsne&#x2F;</a></li><li>+ <a href="https&#x3a;&#x2F;&#x2F;scikit&#x2d;learn&#x2e;org&#x2F;stable&#x2F;modules&#x2F;clustering&#x2e;html">https:&#x2F;&#x2F;scikit-learn.org&#x2F;stable&#x2F;modules&#x2F;clustering.html</a></ul><li>- moving closer to center of the cluster;</li><li>- represented through colour; blurs and shadows;</li><li>- gradient scale: warmth <a href="https&#x3a;&#x2F;&#x2F;en&#x2e;wikipedia&#x2e;org&#x2F;wiki&#x2F;Thermographic&#x5f;camera&#x23;&#x2F;media&#x2F;File&#x3a;Infrared&#x5f;dog&#x2e;jpg">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Thermographic_camera#&#x2F;media&#x2F;File:Infrared_dog.jpg</a></ul></li></ul><li>- alternative to pop up windows:&nbsp;<ul class="indent"><li>- make a quick mock-up of the entry div showing more info;</li><li></ul><li>- switch between images and text tiles;</li><li></li><li>- thumbnails version of all images; resize and crop; set a max-width;</li><li>- should we standardize? even if entries don&#x27;t have a space for images then we can add a placeholder,<ul class="indent"><li>- <a href="https&#x3a;&#x2F;&#x2F;imagemagick&#x2e;org&#x2F;script&#x2F;command&#x2d;line&#x2d;tools&#x2e;php">https:&#x2F;&#x2F;imagemagick.org&#x2F;script&#x2F;command-line-tools.php</a>&nbsp;</li><li>- minimum width of 640 pixels</li><li>- small icon for display on mainpage;</li><li>- hover &#x2F; pop up will have another dimension;</ul></li></ul></li></ul></li></ul><br><strong>- notes on slow iteration:</strong><br><ul class="indent"><li>- possible breakpoints to mark with style:<ul class="indent"><li>- from the beggining to the end of the iteration could we go from background white to dark?</li><li>- <strong>ALL SOUNDS</strong> that are mapped from iteration:</li><li><ul class="indent"><li><strong>&#8212; 00.</strong>- initalize centroids: &quot;NEW CONTROID&quot; (at the beggining of each iteration, same sound for each cluster);<ul class="indent"><li></li><li><strong>&#8212; 01.</strong> (ALGORITHM POSITION) start stage</li><li></li><li><strong>&#8212; 02.</strong> (ALGORITHM POSITION) cluster assignment stage (&quot;deciding&quot;),&nbsp;</li><li></li><li><strong>&#8212; 03.</strong>For each entry:<ul class="indent"><li><strong>&#8212; 03.1.</strong>- &quot;measured&quot; &#8212; distance measurement for a specific entry to a centroid; is linked to pitch (if measurement is 0 then it is silent);</li><li><strong>&#8212; 03.2.</strong>- &quot;reconsidering...&quot; the membership of an entry&nbsp;</li><li><strong>&#8212; 03.3.</strong>- &quot;deciding..&quot;&nbsp;</li><li></ul><li><strong>&#8212; 01. (VISUAL) </strong>open pops-up; like opening &quot;boxes&quot; of a Cabinet of Curiosities <a href="https&#x3a;&#x2F;&#x2F;en&#x2e;wikipedia&#x2e;org&#x2F;wiki&#x2F;Cabinet&#x5f;of&#x5f;curiosities">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Cabinet_of_curiosities</a>&nbsp;<ul class="indent"><li><ul class="indent"><li><ul class="indent"><li><ul class="indent"><li><ul class="indent"><li><ul class="indent"><li><ul class="indent"><li><ul class="indent"><li><ul class="indent"><li><ul class="indent"><li><ul class="indent"><li><ul class="indent"><li>+ <a href="https&#x3a;&#x2F;&#x2F;upload&#x2e;wikimedia&#x2e;org&#x2F;wikipedia&#x2F;commons&#x2F;8&#x2F;82&#x2F;Cabinet&#x5f;of&#x5f;Curiosities&#x5f;1690s&#x5f;Domenico&#x5f;Remps&#x2e;jpg">https:&#x2F;&#x2F;upload.wikimedia.org&#x2F;wikipedia&#x2F;commons&#x2F;8&#x2F;82&#x2F;Cabinet_of_Curiosities_1690s_Domenico_Remps.jpg</a></ul></li></ul></li></ul></li></ul></li></ul></li></ul></li></ul></li></ul></li></ul><li>- <a href="https&#x3a;&#x2F;&#x2F;github&#x2e;com&#x2F;anatomiesofintelligence&#x2F;anatomiesofintelligence&#x2e;github&#x2e;io&#x2F;blob&#x2F;master&#x2F;theatre&#x2e;v3&#x2e;html&#x23;L151">https:&#x2F;&#x2F;github.com&#x2F;anatomiesofintelligence&#x2F;anatomiesofintelligence.github.io&#x2F;blob&#x2F;master&#x2F;theatre.v3.html#L151</a><ul class="indent"><li>- to_do:<ul class="indent"><li>- create a function for pop-up to close;</li><li>- connect open and close to clustering instead of on click event.</ul></li></ul></li></ul></li></ul><li>-note: if the tempo is above a certain speed it does not open pop-ups instead it adds a new style;</ul></li></ul><li><ul class="indent"><li><strong>- 02. (VISUAL) </strong>flickering;<ul class="indent"><li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; animation: flicker 4s linear 1s;</li><li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; @keyframes flicker {</li><li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0% { background-color: white; }</li><li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 25% { background-color: black; }</li><li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 50% { background-color: black; }</li><li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 100% { background-color: white; }</li><li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }</li><li></ul><li><strong>- 03. (VISUAL) </strong>scale each image and manipulate images;&nbsp;<ul class="indent"><li>- reveal the textures;</li><li>- make new patterns;</li><li>-&nbsp; (if removing max-width for images and set width: 100%;), we can then&nbsp;<ul class="indent"><li><ul class="indent"><li><ul class="indent"><li><ul class="indent"><li>img {width: 300%;}</li><li></li><li>animation: scale 30s ease-in-out 1;</li><li>-webkit-animation: slow 30s ease-in-out 2</li><li></li><li>@keyframes scale {</li><li>0%, 100% { transform: scale(1);}</li><li>50% { transform: scale(5);}</li><li>}</ul></li></ul></li></ul></li></ul><li></ul><li><strong>&#8212; 04. (VISUAL) </strong>slow motion;&nbsp;<ul class="indent"><li>-&nbsp; we can define the speed&#x2F;slowness&#x2F;delay in the animation itself:<ul class="indent"><li>.element {</li><li>&nbsp; animation: move 20s ease;&nbsp;</li><li>}</li><li>@keyframes move {</li><li>&nbsp; 0% {</li><li>&nbsp;&nbsp;&nbsp; transform: translate(x, y);</li><li>&nbsp; }</li><li>&nbsp; 100% {</li><li>&nbsp;&nbsp;&nbsp; transform: translate(x, y);</li><li>}</ul><li>-&nbsp; we can have an animation for the entries to move slightly:<ul class="indent"><li>.element {</li><li>&nbsp; animation: move 20s ease infinite alternate;</li><li>}</li><li>@keyframes move {<ul class="indent"><li><ul class="indent"><li>&nbsp; 0%, 100% {</li><li>&nbsp;&nbsp;&nbsp; transform: translate(0, 0);</li><li>&nbsp; }</li><li>&nbsp; 50% {</li><li>&nbsp;&nbsp;&nbsp; transform: translate(50px, 0);</li><li>&nbsp; }</li><li>&nbsp; 80% {</li><li>&nbsp;&nbsp;&nbsp; transform: translate(-50px, 0);</li><li>&nbsp; }</ul></li></ul><li>}</li><li></ul></li></ul><li><strong>- 05. (VISUAL)</strong> each iteration cluster is visualized and one zooms in&#x2F; out;<ul class="indent"><li>- inside the body &quot;transform: scale(3);&quot; &#8212;&gt; more than &quot;3&quot; thumbnails get blurry;</li><li>- we can scale with in the browser with keyboard keys;</ul><li></li><li><strong>&#8212; 04.</strong>(ALGORITHM POSITION) centroid recalculation stage (&quot;recalculating the cluster center for iteration 0&quot;)</li><li></li><li><strong>&#8212; 05.</strong>For each centroid:<ul class="indent"><li>- Recalculate centroid position or Leave Unchanged (&quot;Recalculating the center of catgory 0...&quot;)</ul><li></li><li><strong>&#8212; 06.</strong> (ALGORITHM POSITION) end stage of iteration.</li><li></li><li><strong>(SOUND)</strong> questions: how to overlay voice, and visceral sounds?<ul class="indent"><li>- low pass filter effect&#x2F; silencing;</ul><li></ul><li><strong>(1)</strong> animated gifs &#x2F; other animations of ML processes?<ul class="indent"><li>- css animations;</ul></li></ul><li></ul><li><strong>(1)</strong> expressing multidimensionality<ul class="indent"><li>* 2 Dimension&nbsp;</li><li>* Radial projection (1 dimension);</li><li>References:<ul class="indent"><li><a href="http&#x3a;&#x2F;&#x2F;www&#x2e;internetmoongallery&#x2e;com&#x2F;archive&#x2F;JoanaChicau&#x2F;Theatre&#x5f;of&#x5f;reSources&#x2e;html">http:&#x2F;&#x2F;www.internetmoongallery.com&#x2F;archive&#x2F;JoanaChicau&#x2F;Theatre_of_reSources.html</a></li><li><a href="http&#x3a;&#x2F;&#x2F;rec&#x2d;on&#x2e;org&#x2F;">http:&#x2F;&#x2F;rec-on.org&#x2F;</a></li><li></ul></li></ul><li><strong>(1)</strong> problems with browser lagging and &#x2F; or running out of memory&nbsp;<ul class="indent"><li>- check if we are clearing the interval; or accumulating values;</li><li>- check image quality rediction solves the issue?</ul><li></ul><strong>(1) sound</strong><br><ul class="indent"><li>&nbsp; <strong>(1)</strong> sonification of other commands (e.g. randomize() &#x2F; clean_surface() )?</li><li>&nbsp; (1) exploring &#x27;visceral&#x2F;invasive&#x27; aesthetics</li><li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - a catalog of innervating sounds: flutter (of an organ), crackle, whisper, tears, ...</li><li>&nbsp; <strong>(1)</strong> multiple resolutions of different aspects of algorithm (more details focusing on specific gestures of the algorithms)<ul class="indent"><li><ul class="indent"><li><ul class="indent"><li>- audience awareness work</li><li>- slowing down &#x2F; speeding up</li><li>- silencing certain aspects of the algorithm to foreground others</li><li>- visual equivalents: foregrounding &#x2F; vs backgrounding movement ~~ foregrounding &#x2F; vs backgrounding image &amp; text</li><li>- visceral sound exploration</ul></li></ul></li></ul></li></ul><br>* (general theme) dimensionality reduction<br><ul class="indent"><li><ul class="indent"><li><strong>(1)</strong> principle component analysis &#8212; &gt; goes together with k-means</li><li><strong>(? future research)</strong> T-SNE</li><li><strong>(? future research)</strong> manifold learning <a href="https&#x3a;&#x2F;&#x2F;scikit&#x2d;learn&#x2e;org&#x2F;stable&#x2F;modules&#x2F;manifold&#x2e;html">https:&#x2F;&#x2F;scikit-learn.org&#x2F;stable&#x2F;modules&#x2F;manifold.html</a></ul><li><strong>(1&#x2F;2)</strong> novelty &amp; outlier detection: <a href="https&#x3a;&#x2F;&#x2F;scikit&#x2d;learn&#x2e;org&#x2F;stable&#x2F;modules&#x2F;outlier&#x5f;detection&#x2e;html">https:&#x2F;&#x2F;scikit-learn.org&#x2F;stable&#x2F;modules&#x2F;outlier_detection.html</a></li><li></ul><br><strong>(1) central spreadsheet </strong>&#8212; feature selection &#x2F; tagging and catalog &#8212; cvs &#8212; pulling and changing from hub;<br><ul class="indent"><li><strong>(1)</strong> explore offline processing of catalog entries;</li><li><strong>(1)</strong> write a python script that would automatically move the data to the entries;<ul class="indent"><li><strong>(1)</strong> store features in CSV databases? &#8212; &gt; spreasheet;&nbsp;</ul></li></ul>&nbsp;&nbsp; --- have a meeting to decide on core vocabulary &#x2F; tags<br><ul class="indent"><li><strong>(1)</strong> stricter regulation &amp; featuring of our vocabulary as the featurespace of our catalog</li><li><strong>(1)</strong> offline self-organizing feature suggestions (this becomes possible once we have become more rigorous about our vocab&#x2F;tags)</li><li></li><li></ul><s>* remote? webserver;</s><br><strong>(2)</strong> &#8212; May<br>* movable in-browser console;<br>* material research (?-depending on if extra production funding could come from Zurich)<br>* video take the observer&#x27;s perspective;<br><br><strong>(2)</strong> multi-projection setup:<br><ul class="indent"><li>&nbsp;&nbsp;&nbsp; * 2&#8212;4 projections</li><li>&nbsp;* or 3D representation &#x2F; simple 3D representations in the browser</li><li><strong>(2)</strong> projector setup &#x2F; display of catalog on multiple or layered projection screens</li><li>* floor projection &#x2F; projection stage</li><li>* movement in space ~ dance and movement &#x2F; sculptural movement and representations of multidimensional processes</li><li>* spatial projections?</ul><strong>(2)</strong> performance &#x2F; dramaturgy &#x2F; aesthetics<br><ul class="indent"><li>* speaking together vs apart</li><li>* narrative structure &#x2F; additional writing</li><li>* (concept to explore in embodiment and in catalog) movement vs. stillness :: fluid vs. fixed representation&nbsp;</li><li>* stage: experiment with gauze projections and multi-layer projections&nbsp;<ul class="indent"><li>* embodied aspects<ul class="indent"><li>* movement in space?<ul class="indent"><li>* the fixed bodies of AI;&nbsp;</li><li>* transition of &quot;still&quot; positions;</ul></li></ul></li></ul></li></ul><br>* other algorithms: peruse the sci-kit learn documentation: <a href="https&#x3a;&#x2F;&#x2F;scikit&#x2d;learn&#x2e;org&#x2F;stable&#x2F;unsupervised&#x5f;learning&#x2e;html">https:&#x2F;&#x2F;scikit-learn.org&#x2F;stable&#x2F;unsupervised_learning.html</a><br><ul class="indent"><li>* (belongs to &quot;feature selection&quot;) automated feature creation;</li><li></li><li>* <strong>(? future research)</strong> other clustering algorithms<ul class="indent"><li>* <a href="https&#x3a;&#x2F;&#x2F;scikit&#x2d;learn&#x2e;org&#x2F;stable&#x2F;modules&#x2F;clustering&#x2e;html">https:&#x2F;&#x2F;scikit-learn.org&#x2F;stable&#x2F;modules&#x2F;clustering.html</a></li><li>* <a href="https&#x3a;&#x2F;&#x2F;scikit&#x2d;learn&#x2e;org&#x2F;stable&#x2F;modules&#x2F;mixture&#x2e;html">https:&#x2F;&#x2F;scikit-learn.org&#x2F;stable&#x2F;modules&#x2F;mixture.html</a></ul></li></ul><br>Interesting note from ICLC: do we want to think more &#x2F; emphasize the site specificity of this performance?<br><ul class="indent"><li>tour of anatomical theatres? ^_^ ^_^ !!!</ul><br><br>________________________________________________________<br><strong>ICLC</strong><br><s>&nbsp;&nbsp;&nbsp; print bookelts of clusterings;</s><br>&nbsp;&nbsp;&nbsp; add animation between projections;<br><br>- - - - -&nbsp;<br># transmediale 2020 presentation: Adversarial Hacking Workshop<br><br><strong>## General Description</strong><br><br><strong>- - - website:</strong><br><br>Anatomies of Intelligence is an artistic research initiative seeking to make connections between the formats and collections of anatomical knowledge and investigations into the &#8220;anatomy&#8221; of computational learning and prediction processes, datasets and machine learning models<br><br>We opt for the live algorithmic setting as a way to bring out an embodied presence for existing-with these other bodies&nbsp;<br>Dissective, preparatory and demonstrative gestures lie at the center of our approach<br>and by developing our own demonstration tools and data sets, our methodology brings to surface the artisanal human acts of craft and gesture inherent to such processes<br><br><strong>- - - theatre&#x2F; catalogue:</strong><br><br>We began the project by building an online repository which gathers terminologies and techniques for a critical examination of the &#8220;anatomy&#8221; of learning and prediction processes, data corpora and models of machine learning algorithms.&nbsp;<br><br>This catalog is a living research document into:<br><ul class="indent"><li><ul class="indent"><li><ul class="indent"><li>* the &#x2F; a brief history and present of anatomical science,&nbsp;</ul></li></ul></li></ul>(beginning with the collection, preparation and performance of anatomical knowledge in 18th century Leiden - with its most spectacular demonstration of knowledge - the anatomical theater<br>Reference + Interview &#8212; Elegant Anatomy The Eighteenth-Century Leiden Anatomical Collections By Marieke M. A. Hendriksen<br><ul class="indent"><li><ul class="indent"><li><ul class="indent"><li>* as well as &#8220;anatomies&#8221; of statistical learning systems, data collection and data stewardship practices&nbsp;</ul></li></ul></li></ul><br><br>The catalogue interface is also our platform to explore, through performance, how such an artisanal toolkit can help to&nbsp;<br><ul class="indent"><li>* create new relationships with the bodies of artificial intelligence</li><li>* explore processes of statistical ontology-making</li><li>* and rescale representational structures and learning processes to the measure &#x2F; experience of the human body</ul><br><strong>## Short Presentation of the Catalog + Sonification</strong><br><br>fast demo:<br><ul class="indent"><li><strong>clean_surface()</strong></li><li>TEMPO = 2.0</li><li><strong>catalog.cluster(3, Measures.euclidean, [&quot;cutting&quot;, &quot;measurement&quot;], 20, resultfunc, false, OSC_OUT, console.log)</strong></li><li><strong>project(Projections.SIMPLE2D)</strong></ul><br>slow demo:<br><ul class="indent"><li><strong>catalog.cluster(3, Measures.euclidean, [&quot;elegance&quot;, &quot;aesthesis&quot;], 5, resultfunc, true, OSC_OUT, console.log);</strong></li><li><strong>project(Projections.RADIUS)</strong></li><li><strong>project(Projections.SIMPLE2D)</strong></li><li></li><li><strong>Aesthesis as Analytical Category for an Epistemic Culture&nbsp;</strong></li><li></li><li>Amongst our focus points are those that relate to tacit knowledge and a reliance on the senses when accumulating knowledge about bodies and body-like structures &#8212; in both anatomic and computational practices</li><li></li><li>the concept of aesthesis shapes a methodology for this project that looks at the &#8220;sensory power&#8221; displayed by machine learning algorithms, their representations and sets of training data.&nbsp;</li><li></li><li>Our aim is to engage with different modes of performativity by which these aesthetics emerge, experimenting with different orientations for observation and knowing, and creating a specific vocabulary for our methods based in an anatomical arrangement of parts and systems</ul><br><br>__A Reflection on the Questions of the Workshop__<br>* How can hacking techniques disclose the workings of AI and produce new knowledge and awareness about it?&nbsp;<br>&nbsp;&nbsp;&nbsp; * Aesthesis: make sensory aspects apparent; make sense through the senses; tacit knowledge;<br>&nbsp;&nbsp;&nbsp; * The body as measure of things;&nbsp;<br>&nbsp;&nbsp;&nbsp; * Craft AI method;&nbsp;<br>&nbsp;&nbsp;&nbsp; * Small intimate understandings;&nbsp;<br>&nbsp;&nbsp;&nbsp; * Enlightenment: &#8216;universal&#8217;; colonialism;&nbsp;<br>&nbsp;&nbsp;&nbsp; * Performative: embodied + live: exposing discovery, process and error; force re-engineering of algorithms as by design this algorithmic are made for monolithic black boxes and time scales which are very different than human beings;&nbsp;<br>&nbsp;&nbsp;&nbsp; * Dissection as a mode of exploring; preparation and exploration &#8212; hands on.<br>&nbsp;&nbsp;&nbsp; * Slowness + Closeness;<br><br>We aim at better understanding the habitual and fixed objects of machine learning as well as their terminologies, and construct a new body of counter-techniques.&nbsp;<br><br>from &quot;Collections of Perfection&quot;<br><a href="https&#x3a;&#x2F;&#x2F;www&#x2e;universiteitleiden&#x2e;nl&#x2F;en&#x2F;research&#x2F;research&#x2d;projects&#x2F;humanities&#x2F;collections&#x2d;of&#x2d;perfection">https:&#x2F;&#x2F;www.universiteitleiden.nl&#x2F;en&#x2F;research&#x2F;research-projects&#x2F;humanities&#x2F;collections-of-perfection</a><br><br>&quot;collections (institutional as well as private) generally represented and generated knowledge. Collectors were continuously and consciously making choices as to what they should and should not include. Even more, they chose <em>methods of preservation and ways of exhibiting</em>, involving not only technical skills but also cultural ideas and ideals. Anatomical exhibits, in other words, were made objects. They were meant to show the anatomy of the body (according to contemporary physiological ideas), but were at the same time portraits of their makers, of their image of the ideal body and of the intimate experience of their own body&quot;<br><br>- - - - -&nbsp;<br><br><br><strong>Notes on performance-lecture</strong><br>Second Clustering: Collection and Preparation<br>what about &quot;Parts of a Monster&quot;? -&gt; <a href="https&#x3a;&#x2F;&#x2F;anatomiesofintelligence&#x2e;github&#x2e;io&#x2F;posts&#x2F;2019&#x2d;12&#x2d;6&#x2d;monster&#x5f;instruments">https:&#x2F;&#x2F;anatomiesofintelligence.github.io&#x2F;posts&#x2F;2019-12-6-monster_instruments</a><br>or should we add another clustering on &quot;perfection&quot; and &quot;monsters&quot;?<br>When mentioning the way decisions are made about how an item enters a collection: relating to K-means and other &quot;similarity&quot; or &quot;cost&quot; functions<br><a href="https&#x3a;&#x2F;&#x2F;anatomiesofintelligence&#x2e;github&#x2e;io&#x2F;posts&#x2F;2019&#x2d;09&#x2d;24&#x2d;Euclidean&#x5f;Distance">https:&#x2F;&#x2F;anatomiesofintelligence.github.io&#x2F;posts&#x2F;2019-09-24-Euclidean_Distance</a><br>&gt; on creating classifications &gt; <a href="https&#x3a;&#x2F;&#x2F;anatomiesofintelligence&#x2e;github&#x2e;io&#x2F;posts&#x2F;2019&#x2d;06&#x2d;21&#x2d;conceptual&#x2d;clustering">https:&#x2F;&#x2F;anatomiesofintelligence.github.io&#x2F;posts&#x2F;2019-06-21-conceptual-clustering</a><br>&gt; an additional movement&#x2F;clustering or more material specifically discussing the poetics of attempting to understand high-dimensional spaces and the different &quot;cuts&quot; of anatomy, consider researching the notion of a &quot;body&quot;, a &quot;data corpus&quot;, for performative exposition<br>&gt; the typing of the algorithm should slower or maybe read out loud so the audience can follow the selection of &#x27;tags&#x27;.<br>&gt; Monsters &#x2F; &quot;Freakish Incidents or Devil&#x27;s Work or Unknown Categories&quot;&nbsp; VS &quot;Anomaly detection<em>&quot; &#x2F; k</em>-NN &#x2F; Local outlier factor ...<br><br>&gt; Magda: these hands-on, material practices with data and algorithms can work as a countermeasure against obfuscation and anthropomorphizing &quot;AI&quot;. Valuable to ask: &quot;who benefits from such obfuscation?&quot; &gt; the attitude of &quot;I don&#x27;t get computers&quot; has grown into an absolute impossibility of understanding for most people in relation to &quot;AI&quot;<br><br>&gt; consider parallels in the arts in this period: poetry reading describing one&#x27;s loved one for the spectacle for other men. Other spectacles of the period that could help support the theory of an epistemic preference for theatre as medium?<br><br>&gt; Consider dataset making as storytelling :: our dataset&#x2F;tags and weights are set in the performance to help us tell a story.<br><br>&gt; How do we use collage and juxtaposition to tell a story? Winnie feels this is a very strong part of the performance.<br><br><strong>Notes on workshop</strong><br>Second Clustering: Collection and Preparation<br>&gt; when using regression the unrepresented entries when clustering also are vizualized.<br>&gt; chosen tags:<br>&nbsp;&nbsp;&nbsp; &gt; geometry and inside&#x2F;out<br>&nbsp;&nbsp;&nbsp; &gt; group 02: cutteness and curliness<br>&gt; Winnie and Anders define the exemplars in the dataset that define the laest and maximum values of there tags; from there they assigned the values (weights) to the rest of the dataset.<br>&gt; Magda recommends looking into other uses of the term &quot;aesthesis&quot; in earlier histories as relating to art &amp; performance<br>&gt; Winnie asks: what is our approach to choosing features that describe broader vs. specific concepts, or concepts that in many ways could be considered heirarchical. For example: Machine Learning, RNN, CNN, LSTM are tags - all of them are in some sense machine learning, and LSTM is a more specific type of RNN<br>&gt; Magda finds our method very interesting&#x2F;valuable. She encourages the combination of performance + followup workshop to explore the concepts.<br><br><br>&gt; how can we develop exercises that make sensible the &#x27;weights&#x27;? like gravitational forces&#x2F; weight transfer physical movement types.<br><strong>&gt; get in touch with Welcome Collection and refer to workshop;</strong><br><br><strong><em>Some General reflections:</em></strong><br>&gt; Can we do more research, with a focus on exploring topics such as dimensionality, topology, and cuts<br>&gt; More research into the visualization of n dimensional space<br>&gt; another terminology from deep learning, overcoming the problem of sparseness and the curse of dimensionality: &quot;lower dimensional embeddings&quot; <a href="https&#x3a;&#x2F;&#x2F;developers&#x2e;google&#x2e;com&#x2F;machine&#x2d;learning&#x2F;crash&#x2d;course&#x2F;embeddings&#x2F;translating&#x2d;to&#x2d;a&#x2d;lower&#x2d;dimensional&#x2d;space">https:&#x2F;&#x2F;developers.google.com&#x2F;machine-learning&#x2F;crash-course&#x2F;embeddings&#x2F;translating-to-a-lower-dimensional-space</a><br><a href="https&#x3a;&#x2F;&#x2F;developers&#x2e;google&#x2e;com&#x2F;machine&#x2d;learning&#x2F;crash&#x2d;course&#x2F;embeddings&#x2F;video&#x2d;lecture">https:&#x2F;&#x2F;developers.google.com&#x2F;machine-learning&#x2F;crash-course&#x2F;embeddings&#x2F;video-lecture</a><br><a href="https&#x3a;&#x2F;&#x2F;en&#x2e;wikipedia&#x2e;org&#x2F;wiki&#x2F;Embedding">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Embedding</a><br><br>&gt; nonlinear dimensionality reduction: <a href="https&#x3a;&#x2F;&#x2F;en&#x2e;wikipedia&#x2e;org&#x2F;wiki&#x2F;Nonlinear&#x5f;dimensionality&#x5f;reduction">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Nonlinear_dimensionality_reduction</a><br>&gt; other dimensionality reduction algorithms: <a href="https&#x3a;&#x2F;&#x2F;lvdmaaten&#x2e;github&#x2e;io&#x2F;tsne&#x2F;">https:&#x2F;&#x2F;lvdmaaten.github.io&#x2F;tsne&#x2F;</a><br><a href="https&#x3a;&#x2F;&#x2F;en&#x2e;wikipedia&#x2e;org&#x2F;wiki&#x2F;T&#x2d;distributed&#x5f;stochastic&#x5f;neighbor&#x5f;embedding">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;T-distributed_stochastic_neighbor_embedding</a><br><br><br>&gt; Research into data cleanup and normalization techniques<br>&gt; Research into linear, quadratic, and non-linear models&#x2F;bodies&#x2F;movements<br>&gt; Potential topics for future performance&#x2F;workshops (in the spirit of K-means): Autoencoders &#x2F; Compression, Support Vector Machines, Principle Component Analysis<br><br>&gt;&gt; Other examples: AI as a shock and delight, a performance spectacle: e.g. The Mechanical Turk &amp; Automata<br>GAN<br>Ibmdeep blue<br>Alpha Go<br><br><br><br><br><strong>Transmediale</strong><br><a href="https&#x3a;&#x2F;&#x2F;2020&#x2e;transmediale&#x2e;de&#x2F;content&#x2F;adversarial&#x2d;hacking&#x2d;in&#x2d;the&#x2d;age&#x2d;of&#x2d;ai&#x2d;call&#x2d;for&#x2d;proposals">https:&#x2F;&#x2F;2020.transmediale.de&#x2F;content&#x2F;adversarial-hacking-in-the-age-of-ai-call-for-proposals</a><br><br><strong>Blurb &#x2F; Concept: Proposal for a live coding @Transmediale</strong><br>A series of audio-visual performances connected via different systems: from online to offline presences; from hand-crafted interfaces to appropriated platforms &#8212; creating a mesh of real-time algorithmic composition (1) exploring the possibilities of ...dancing agents within networks &#x2F; or (2) what networks can be in a dance with no end.<br><br><em>Other materialities to be explored:</em><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; printed matter: for cross-reading sessions during interludes, and for the audience to take home;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; code repo on a local internet: a code repo could be made available and circulated on a local wi-fi.<br><br>Performers that will be in Berlin during Transmediale and local community: Jonathan Reus (<a href="https&#x3a;&#x2F;&#x2F;jonathanreus&#x2e;com&#x2F;">https:&#x2F;&#x2F;jonathanreus.com&#x2F;</a> ) Joana Chicau (<a href="http&#x3a;&#x2F;&#x2F;www&#x2e;joanachicau&#x2e;com&#x2F;">http:&#x2F;&#x2F;www.joanachicau.com&#x2F;</a> ) Codie (<a href="https&#x3a;&#x2F;&#x2F;codie&#x2e;live&#x2F;">https:&#x2F;&#x2F;codie.live&#x2F;</a> ) Ulysses Popple (<a href="https&#x3a;&#x2F;&#x2F;www&#x2e;youtube&#x2e;com&#x2F;c&#x2F;UlyssesPopple">https:&#x2F;&#x2F;www.youtube.com&#x2F;c&#x2F;UlyssesPopple</a> ) Alexandra Cardenas (<a href="https&#x3a;&#x2F;&#x2F;cargocollective&#x2e;com&#x2F;tiemposdelruido&#x2F;Alexandra&#x2d;Cardenas">https:&#x2F;&#x2F;cargocollective.com&#x2F;tiemposdelruido&#x2F;Alexandra-Cardenas</a> ) also based in Berlin: Hlodver Sigurdsson (<a href="https&#x3a;&#x2F;&#x2F;www&#x2e;youtube&#x2e;com&#x2F;channel&#x2F;UCsC&#x5f;IIIIjZkc8DgooZmYuiw">https:&#x2F;&#x2F;www.youtube.com&#x2F;channel&#x2F;UCsC_IIIIjZkc8DgooZmYuiw</a> ) Calum Gunn (<a href="http&#x3a;&#x2F;&#x2F;www&#x2e;calumgunn&#x2e;com&#x2F;">http:&#x2F;&#x2F;www.calumgunn.com&#x2F;</a> )<br><br><strong><s>Deadline </s></strong><s>&#8212; 15 December 2019 &#8212; </s><a href="https&#x3a;&#x2F;&#x2F;versal&#x2e;submittable&#x2e;com&#x2F;submit"><s>https:&#x2F;&#x2F;versal.submittable.com&#x2F;submit</s></a><s> (15dollars submission fee)</s><br><br>- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -&nbsp;<br><br>Priorities:<br><s>* email Magda <strong>&gt; Joana&nbsp;</strong></s><br><ul class="indent"><li><ul class="indent"><li><s>&gt; about physical exercises (ask for matresses)</s></li><li><s>&gt; do we need to get the bus tickets?</s></li><li><s>&gt; bring confortable clothes + own laptops and data sets of interest; no previous machine learning &#x2F; programming knowledge required.</s></li><li><s>&gt; participants should read the project description of: </s><a href="https&#x3a;&#x2F;&#x2F;www&#x2e;universiteitleiden&#x2e;nl&#x2F;en&#x2F;research&#x2F;research&#x2d;projects&#x2F;humanities&#x2F;collections&#x2d;of&#x2d;perfection"><s>https:&#x2F;&#x2F;www.universiteitleiden.nl&#x2F;en&#x2F;research&#x2F;research-projects&#x2F;humanities&#x2F;collections-of-perfection</s></a></li><li>&gt; select + send to Magda a selection of 20 images + source from anatomic collections (print 1 set per group)</li><li><s>@<strong>Jonathan</strong> please check: </s><a href="https&#x3a;&#x2F;&#x2F;github&#x2e;com&#x2F;anatomiesofintelligence&#x2F;anatomiesofintelligence&#x2e;github&#x2e;io&#x2F;tree&#x2F;master&#x2F;folder&#x5f;dataset"><s>https:&#x2F;&#x2F;github.com&#x2F;anatomiesofintelligence&#x2F;anatomiesofintelligence.github.io&#x2F;tree&#x2F;master&#x2F;folder_dataset</s></a></ul></li></ul><br><strong>TODO:</strong><br><s>* Change color value <strong>&gt; Joana&nbsp;</strong></s><br><s>Line 344: </s><a href="https&#x3a;&#x2F;&#x2F;github&#x2e;com&#x2F;anatomiesofintelligence&#x2F;anatomiesofintelligence&#x2e;github&#x2e;io&#x2F;blob&#x2F;master&#x2F;theatre&#x5f;projection&#x2e;html"><s>https:&#x2F;&#x2F;github.com&#x2F;anatomiesofintelligence&#x2F;anatomiesofintelligence.github.io&#x2F;blob&#x2F;master&#x2F;theatre_projection.html</s></a><br><s>* add new entry on&nbsp; </s><a href="https&#x3a;&#x2F;&#x2F;en&#x2e;wikipedia&#x2e;org&#x2F;wiki&#x2F;Frederik&#x5f;Ruysch&#x23;cite&#x5f;note&#x2d;1"><s>https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Frederik_Ruysch#cite_note-1</s></a><s> + </s><a href="http&#x3a;&#x2F;&#x2F;www&#x2e;zymoglyphic&#x2e;org&#x2F;exhibits&#x2F;ruysch&#x2e;html"><s>http:&#x2F;&#x2F;www.zymoglyphic.org&#x2F;exhibits&#x2F;ruysch.html</s></a><s>&nbsp;</s><br><s>* Radius projection (maps euclidean distance between the centroid and entry)</s><br><s>* 2D (browser as 2D space:; maps the clusters according to tag; tags become coordinates)</s><br><s>* remove or change Metafont;</s><br><strong>TODO on the way:</strong><br><s>&gt; Revise cluster tags according to: </s><a href="https&#x3a;&#x2F;&#x2F;github&#x2e;com&#x2F;anatomiesofintelligence&#x2F;anatomiesofintelligence&#x2e;github&#x2e;io&#x2F;blob&#x2F;master&#x2F;lecture&#x5f;preformance&#x2e;md"><s>https:&#x2F;&#x2F;github.com&#x2F;anatomiesofintelligence&#x2F;anatomiesofintelligence.github.io&#x2F;blob&#x2F;master&#x2F;lecture_preformance.md</s></a><br><s>to use during lecture as eg.: catalog.cluster(2, Measures.euclidean, [&quot;theatre&quot;, &quot;aesthesis&quot;, &quot;spectacle&quot;], 10, resultfunc, false)</s><br><s>&gt; Add ML and K-means explanation of the k-means clustering + multiple-dimensionality: see file on github &gt; <strong>workshop_presentation.html </strong></s><a href="https&#x3a;&#x2F;&#x2F;anatomiesofintelligence&#x2e;github&#x2e;io&#x2F;workshop&#x5f;presentation&#x2e;html"><s>https:&#x2F;&#x2F;anatomiesofintelligence.github.io&#x2F;workshop_presentation.html</s></a><br><s>&gt; Check exercises + questions &#8212; edit here: </s><a href="https&#x3a;&#x2F;&#x2F;github&#x2e;com&#x2F;anatomiesofintelligence&#x2F;anatomiesofintelligence&#x2e;github&#x2e;io&#x2F;blob&#x2F;master&#x2F;workshop&#x5f;presentation&#x2e;html"><s>https:&#x2F;&#x2F;github.com&#x2F;anatomiesofintelligence&#x2F;anatomiesofintelligence.github.io&#x2F;blob&#x2F;master&#x2F;workshop_presentation.html</s></a><br><strong><s>Minor adjustments:</s></strong><s> colour of centroids;</s><br><strong><s>&gt; PRINT</s></strong><br><s>* Program performance;</s><br><s>* Dataset workshop;</s><br><br><strong>&gt; Update from PDF to Github:</strong><br>* <a href="https&#x3a;&#x2F;&#x2F;github&#x2e;com&#x2F;anatomiesofintelligence&#x2F;anatomiesofintelligence&#x2e;github&#x2e;io&#x2F;blob&#x2F;master&#x2F;lecture&#x5f;preformance&#x2e;md">https:&#x2F;&#x2F;github.com&#x2F;anatomiesofintelligence&#x2F;anatomiesofintelligence.github.io&#x2F;blob&#x2F;master&#x2F;lecture_preformance.md</a><br><br><br><strong><em><u>30 Sept, 2019 ~~~ Skype with Jo, Jon, Magda_________________________________________________________________________________________</u></em></strong><br><br><strong><em>TODO:</em></strong><br>Magda needs this week for PR:<br><ul class="indent"><li></li><li>* workshop: short paragraph, with a description of the workshop give people an idea what to expect and what they will be doing. Do they need to prepare anything, do they need to bring a computer, etc... readings to prepare, datasets etc... &gt;&gt; outcomes &#x2F; challenges for participants</li><li>do we want helpful if participants have basic knolwedge on ML &#x2F; or no previous knowledge required.</li><li>&gt;&gt;&gt; have a nice discussion about the link between clustering and concepts of Euclidean space (an &#x27;anatomical space&#x27; could be a counterproposal?)</li><li></li><li>Following a lecture-performance the previous day, Joana Chicau and Jonathan Reus will share their approach in a public workshop where we will actively explore terminologies and techniques for an &#8220;anatomical&#8221; critique of computational learning, classifying and prediction processes.</li><li>In our session we will focus specifically on the unsupervised clustering algorithm <em>K-means</em> and collectively deconstruct its underlying assumptions of (Euclidean) space and distance.&nbsp;</li><li>Core to the workshop will be a consideration of data classification and clustering. What different knowledge ontologies emerge through other geometries and directionalities based in bodily experiences and physicalities? What is a unit of anatomical space and how can that inform embodied approaches to machine learning?&nbsp;</li><li>Participants are invited to bring their own laptops and data sets of interest; no previous machine learning &#x2F; programming knowledge required.</li><li>Website: <a href="https&#x3a;&#x2F;&#x2F;anatomiesofintelligence&#x2e;github&#x2e;io&#x2F;"><u>https:&#x2F;&#x2F;anatomiesofintelligence.github.io&#x2F;</u></a></li><li></li><li>* presentation&#x2F;performance: short paragraph + bios + images</ul><br><ul class="indent"><li>* details and readings can be sent later on.</ul><br>Location for performance:<br><ul class="indent"><li>* performance: <a href="http&#x3a;&#x2F;&#x2F;cavi&#x2e;au&#x2e;dk&#x2F;">http:&#x2F;&#x2F;cavi.au.dk&#x2F;</a></li><li>* workshop: meeting room;</ul><br><strong><em>______________________________________________________________________________________________________________________________________</em></strong><br><br>Thinking (how to keep the connection in this project to corporeality, a feeling of embodiment) ~~~<br><br>* look at ML &amp; AI-based techniques used in medicine<br><ul class="indent"><li>* A now-classic example of where ML has shown great potential is in medical imaging &amp; classification of cancers<ul class="indent"><li>* Pigeons can also be trained to detect anomalies in medical images (biological neural network!) <a href="https&#x3a;&#x2F;&#x2F;www&#x2e;scientificamerican&#x2e;com&#x2F;article&#x2F;using&#x2d;pigeons&#x2d;to&#x2d;diagnose&#x2d;cancer&#x2F;">https:&#x2F;&#x2F;www.scientificamerican.com&#x2F;article&#x2F;using-pigeons-to-diagnose-cancer&#x2F;</a></ul><li><ul class="indent"><li></ul></li></ul>* Key concepts of anatomical relationship<br><br><ul class="indent"><li>*<a href="https&#x3a;&#x2F;&#x2F;en&#x2e;wikipedia&#x2e;org&#x2F;wiki&#x2F;Anatomical&#x5f;terms&#x5f;of&#x5f;location">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Anatomical_terms_of_location</a> (general reference on western anatomical terminologies)<ul class="indent"><li>&nbsp;*&quot;All descriptions are with respect to the organism in its <strong>standard anatomical position</strong>, even when the organism in question has appendages in another position. This helps avoid confusion in terminology when referring to the same organism in different postures. &quot;&nbsp;<ul class="indent"><li>* Planes &#8212; &gt; <a href="https&#x3a;&#x2F;&#x2F;en&#x2e;wikipedia&#x2e;org&#x2F;wiki&#x2F;Anatomical&#x5f;terms&#x5f;of&#x5f;location&#x23;&#x2F;media&#x2F;File&#x3a;Human&#x5f;anatomy&#x5f;planes&#x2c;&#x5f;labeled&#x2e;jpg">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Anatomical_terms_of_location#&#x2F;media&#x2F;File:Human_anatomy_planes,_labeled.jpg</a><ul class="indent"><li>* Longitudinal plane<ul class="indent"><li><ul class="indent"><li><ul class="indent"><li>* Frontal plane or coronal plane divides the body into dorsal and ventral (back and front, or posterior and anterior) portions.</li><li>* Sagittal plane: Y-Z</ul></li></ul></li></ul><li>* Transverse (also known as horizontal) plane is an X-Z plane&nbsp;</li><li>* Coronal (also known as frontal) plane is a X-Y plane, perpendicular to the ground.</ul></li></ul><li></ul><li>* orientation<ul class="indent"><li>* Sinistral and dextral ( in some scientific fields, are the two types of chirality (&quot;handedness&quot;) or relative direction.)</li><li>* Handedness &#x2F; Laterality (is the preference most humans show for one side of their body over the other.)</li><li>* Proper right and proper left; are conceptual terms used to unambiguously convey relative direction when describing an image or other object; used in medical contexts such as x-ray images.</ul></li></ul><br><ul class="indent"><li>* distance<ul class="indent"><li>* The terms <strong>proximal</strong> (from Latin&nbsp;<em> proximus</em>, meaning &#x27;nearest&#x27;) and <strong>distal</strong> (from Latin&nbsp;<em> distare</em>, meaning &#x27;to stand away from&#x27;) are used to describe parts of a feature that are close to or distant from the main mass of the body, respectively.</li><li>* Superficial and deep: these two terms relate to the distance of a structure from the surface of an animal.</li><li>* Relational <strong>Anatomical landmarks:</strong><ul class="indent"><li>* The location of anatomical structures can also be described with relation to different anatomical landmarks. Structures may be described as being at the level of a specific spinal vertebra, depending on the section of the vertebral column the structure is at. The position is often abbreviated. For example, structures at the level of the fourth cervical vertebra may be abbreviated as &quot;C4&quot;, at the level of the fourth thoracic vertebra &quot;T4&quot;, and at the level of the third lumbar vertebra &quot;L3&quot;.&nbsp;</li><li>* <strong>Anatomical lines</strong>, theoretical lines drawn through structures, are also used to describe anatomical location. For example, the mid-clavicular line is used as part of the cardiac exam in medicine to feel the apex beat of the heart.&nbsp;</ul><li>* Chinese acupuncture notations on distance (flattened view): the location of acupoints and the paths of the channels at the back of the body.&nbsp;</li><li>The units of measurement are the <em>chi</em> and <em>cun</em>, the length of the <em>cun</em> being based on the proportions of the individual&#x27;s body, i.e. 1 <em>cun</em> = the distance from the base of the middle finger to the end of the crease of the middle joint. 10 <em>cun</em> = 1 <em>chi</em>.</li><li><a href="https&#x3a;&#x2F;&#x2F;anatomiesofintelligence&#x2e;github&#x2e;io&#x2F;posts&#x2F;2019&#x2d;09&#x2d;24&#x2d;Body&#x2d;Measurements&#x2d;01">https:&#x2F;&#x2F;anatomiesofintelligence.github.io&#x2F;posts&#x2F;2019-09-24-Body-Measurements-01</a></li><li></ul><li>* direction<ul class="indent"><li>* Directional references: <a href="https&#x3a;&#x2F;&#x2F;en&#x2e;wikipedia&#x2e;org&#x2F;wiki&#x2F;Anatomical&#x5f;terms&#x5f;of&#x5f;location&#x23;&#x2F;media&#x2F;File&#x3a;Blausen&#x5f;0019&#x5f;AnatomicalDirectionalReferences&#x2e;png">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Anatomical_terms_of_location#&#x2F;media&#x2F;File:Blausen_0019_AnatomicalDirectionalReferences.png</a></li><li>* Axes &#x2F; &quot;Directed towards&quot; &#8212; &gt; <a href="https&#x3a;&#x2F;&#x2F;en&#x2e;wikipedia&#x2e;org&#x2F;wiki&#x2F;Anatomical&#x5f;terms&#x5f;of&#x5f;location&#x23;&#x2F;media&#x2F;File&#x3a;Anatomical&#x5f;Directions&#x5f;and&#x5f;Axes&#x2e;JPG">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Anatomical_terms_of_location#&#x2F;media&#x2F;File:Anatomical_Directions_and_Axes.JPG</a>&nbsp;</li><li>* Rotational direction: <strong>Anteversion</strong> and <strong>retroversion</strong> are complementary anatomical terms of location, describing the degree to which an anatomical structure is rotated forwards (towards the front of the body) or backwards (towards the back of the body) respectively, relative to some datum position.&nbsp;</li><li></ul><li>* proportion<ul class="indent"><li>* from various times: <a href="https&#x3a;&#x2F;&#x2F;wellcomecollection&#x2e;org&#x2F;works&#x3f;query&#x3d;proportion">https:&#x2F;&#x2F;wellcomecollection.org&#x2F;works?query=proportion</a></li><li>* here is an article on measurement systems of ancient Egypt and their connection to body proportions: <a href="http&#x3a;&#x2F;&#x2F;www&#x2e;legon&#x2e;demon&#x2e;co&#x2e;uk&#x2F;metrorev&#x2e;htm">http:&#x2F;&#x2F;www.legon.demon.co.uk&#x2F;metrorev.htm</a></li><li>*&nbsp; &quot;The proportions of the human body according to Vitruvius&quot; <a href="https&#x3a;&#x2F;&#x2F;en&#x2e;wikipedia&#x2e;org&#x2F;wiki&#x2F;Vitruvian&#x5f;Man">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Vitruvian_Man</a></li><li>* field of ergonomics (<a href="https&#x3a;&#x2F;&#x2F;en&#x2e;wikipedia&#x2e;org&#x2F;wiki&#x2F;Human&#x5f;factors&#x5f;and&#x5f;ergonomics&#x29;">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Human_factors_and_ergonomics)</a></li><li></ul><li>* symmetry<ul class="indent"><li>* reflection symmetry &#x2F; bilaterally symmetric.</li><li>* asymmetrical and spherical organisms</ul></li></ul><br><ul class="indent"><li>* divergence</li><li></li><li><strong>* Prefixes, suffixes, and other modifiers:</strong> Directional and locational prefixes can modify many anatomical and morphological terms, sometimes in formally standard usage, but often attached arbitrarily according to need or convenience.&nbsp;<ul class="indent"><li>Sub- &#x2F; Hypo- &#x2F; Infra- &#x2F; Inter- &#x2F; Super- &#x2F; Supra- &#x2F; -ad</li><li></ul></li></ul>Others&#x2F; more:<br>{notes on distance: <a href="http&#x3a;&#x2F;&#x2F;www&#x2e;internetmoongallery&#x2e;com&#x2F;archive&#x2F;JoanaChicau&#x2F;Theatre&#x5f;of&#x5f;reSources&#x2e;html">http:&#x2F;&#x2F;www.internetmoongallery.com&#x2F;archive&#x2F;JoanaChicau&#x2F;Theatre_of_reSources.html</a>}<br><ul class="indent"><li>* Early Babylonian and Egyptian records and the Hebrew Bible indicate that length was first measured with the forearm, hand, or finger and that time was measured by the periods of the sun, moon, and other heavenly bodies. <a href="https&#x3a;&#x2F;&#x2F;en&#x2e;wikipedia&#x2e;org&#x2F;wiki&#x2F;History&#x5f;of&#x5f;measurement">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;History_of_measurement</a>&nbsp;</li><li>* The <strong>palm</strong> is an obsolete anthropic unit of length, originally based on the width of the human palm and then variously standardized. The same name is also used for a second, rather larger unit based on the length of the human hand.The width of the palm was a traditional unit in Ancient Egypt, Israel, Greece, and Rome and in medieval England, where it was also known as the <strong>hand</strong>, <strong>handbreadth</strong>. Detail of the cubit rod in the Museo Egizio of Turin, showing digit, palm, hand and fist lengths: <a href="https&#x3a;&#x2F;&#x2F;en&#x2e;wikipedia&#x2e;org&#x2F;wiki&#x2F;Palm&#x5f;&#x28;unit&#x29;&#x23;&#x2F;media&#x2F;File&#x3a;Coud&#x25;C3&#x25;A9e&#x2d;turin&#x5f;detail&#x2e;jpg">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Palm_(unit)#&#x2F;media&#x2F;File:Coud%C3%A9e-turin_detail.jpg</a></li><li>* The Ancient Greek palm (Greek: &#960;&#945;&#955;&#945;&#953;&#963;&#964;&#942;, <em>palaist&#7703;</em>, &#948;&#8182;&#961;&#959;&#957;, <em>d&#333;&#770;ron</em>, or &#948;&#945;&#954;&#964;&#965;&#955;&#959;&#948;&#972;&#967;&#956;&#951;, <em>daktylod&#243;khm&#275;</em>)[11] made up &#188; of the Greek foot (<em>po&#251;s</em>), which varied by region between 27&#8211;35 cm (11 in&#8211;1 ft 2 in).</li><li>* The Roman palm (Latin: <em>palmus</em>) or lesser palm (<em>palmus minor</em>) made up &#188; of the Roman foot (<em>pes</em>), which varied in practice between 29.2&#8211;29.7 cm (11.5&#8211;11.7 in).</li><li>* English units of length: <a href="https&#x3a;&#x2F;&#x2F;en&#x2e;wikipedia&#x2e;org&#x2F;wiki&#x2F;Palm&#x5f;&#x28;unit&#x29;&#x23;&#x2F;media&#x2F;File&#x3a;English&#x5f;length&#x5f;units&#x5f;graph&#x2e;png">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Palm_(unit)#&#x2F;media&#x2F;File:English_length_units_graph.png</a></li><li>* UK&nbsp; weights and measures: <a href="https&#x3a;&#x2F;&#x2F;wellcomecollection&#x2e;org&#x2F;works&#x2F;d7nzyf2w">https:&#x2F;&#x2F;wellcomecollection.org&#x2F;works&#x2F;d7nzyf2w</a></li><li>* The <strong>foot</strong> (pl. <strong>feet</strong>; abbreviation: <strong>ft</strong>; symbol: <strong>&#8242;</strong>, the prime symbol) is a unit of length in the imperial and US customary systems of measurement.&nbsp;</li><li>* <strong>Hair spaces </strong>around dashes: <a href="https&#x3a;&#x2F;&#x2F;en&#x2e;wikipedia&#x2e;org&#x2F;wiki&#x2F;Whitespace&#x5f;character&#x23;Hair&#x5f;spaces&#x5f;around&#x5f;dashes">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Whitespace_character#Hair_spaces_around_dashes</a></ul>{<strong>Blocking (stage):</strong> In theatre, <strong>blocking</strong> is the precise staging of actors in order to facilitate the performance of a play, ballet, film or opera (...) Each scene in a play is usually &quot;blocked&quot; as a unit, after which the director will move on to the next scene.}<br>{<strong>Six degrees of freedom</strong> (<strong>6DoF</strong>) refers to the freedom of movement of a rigid body in three-dimensional space. For e.g. used in robotics}<br><br>* Key concepts &amp; Metaphors from ML&#x2F;AI<br><ul class="indent"><li></li><li>* <strong>distance</strong> (important judgement at the core of K-means)<ul class="indent"><li>* Research references on the use of different distance measurements in K-means algorithms:<ul class="indent"><li>* a study on the effect of different distance measures:&nbsp;</li><li>... K-Medoids?</li><li><a href="https&#x3a;&#x2F;&#x2F;www&#x2e;researchgate&#x2e;net&#x2F;publication&#x2F;262732973&#x5f;Effect&#x5f;of&#x5f;Different&#x5f;Distance&#x5f;Measures&#x5f;on&#x5f;the&#x5f;Performance&#x5f;of&#x5f;K&#x2d;Means&#x5f;Algorithm&#x5f;An&#x5f;Experimental&#x5f;Study&#x5f;in&#x5f;Matlab">https:&#x2F;&#x2F;www.researchgate.net&#x2F;publication&#x2F;262732973_Effect_of_Different_Distance_Measures_on_the_Performance_of_K-Means_Algorithm_An_Experimental_Study_in_Matlab</a></li><li>* some alternative distance measurements used commonly for K-means: <strong><em>sqEuclidean, cityblock, cosine, correlation and Hamming</em></strong></li><li>* proposal for <strong><em>Max-min</em></strong> distance measure <a href="https&#x3a;&#x2F;&#x2F;ieeexplore&#x2e;ieee&#x2e;org&#x2F;document&#x2F;5156398">https:&#x2F;&#x2F;ieeexplore.ieee.org&#x2F;document&#x2F;5156398</a></li><li>* discussion of distance measurements for K-means on Researchgate:&nbsp;<ul class="indent"><li>There are actually plenty of different distance measures that can be used in a clustering problem, e.g., Manhattan distance, Chebychev distance, Spearman correlation, Minkowski metric as a generalization of Euclidean and Manhattan distances and edit distance.&nbsp;</li><li>...<ul class="indent"><li>Found this source on the latter:&nbsp;</li><li><a href="https&#x3a;&#x2F;&#x2F;dzone&#x2e;com&#x2F;articles&#x2F;machine&#x2d;learning&#x2d;measuring">https:&#x2F;&#x2F;dzone.com&#x2F;articles&#x2F;machine-learning-measuring</a></li><li><a href="https&#x3a;&#x2F;&#x2F;towardsdatascience&#x2e;com&#x2F;importance&#x2d;of&#x2d;distance&#x2d;metrics&#x2d;in&#x2d;machine&#x2d;learning&#x2d;modelling&#x2d;e51395ffe60d">https:&#x2F;&#x2F;towardsdatascience.com&#x2F;importance-of-distance-metrics-in-machine-learning-modelling-e51395ffe60d</a></li><li><a href="https&#x3a;&#x2F;&#x2F;towardsdatascience&#x2e;com&#x2F;how&#x2d;to&#x2d;measure&#x2d;distances&#x2d;in&#x2d;machine&#x2d;learning&#x2d;13a396aa34ce">https:&#x2F;&#x2F;towardsdatascience.com&#x2F;how-to-measure-distances-in-machine-learning-13a396aa34ce</a><ul class="indent"><li></li><li>A <strong>distance function</strong> provides distance between the elements of a set. If the distance is zero then elements are equivalent else they are different from each other. (Basic Definition from Math.net)</li><li></li><li><strong>K-Nearest Neighbors(KNN)</strong></li><li><strong>Classification: </strong>in K-means is a non-probabilistic supervised learning algorithm i.e.</li><li><strong>Clustering: </strong>K-means In classification algorithms, probabilistic or non-probabilistic we will be provided with labeled data so, it gets easier to predict the classes. Though in clustering algorithm we have no information on which data point belongs to which class. Distance metrics are important part of these kind of algorithm.</li><li>In K-means, we select number of centroids that define number of clusters. <em>Each data point will then be assigned to its nearest centroid using distance metric (Euclidean)</em>.</li><li></li><li>Introducing K-means clustering example: <a href="https&#x3a;&#x2F;&#x2F;colab&#x2e;research&#x2e;google&#x2e;com&#x2F;github&#x2F;jakevdp&#x2F;PythonDataScienceHandbook&#x2F;blob&#x2F;master&#x2F;notebooks&#x2F;05&#x2e;11&#x2d;K&#x2d;Means&#x2e;ipynb">https:&#x2F;&#x2F;colab.research.google.com&#x2F;github&#x2F;jakevdp&#x2F;PythonDataScienceHandbook&#x2F;blob&#x2F;master&#x2F;notebooks&#x2F;05.11-K-Means.ipynb</a></ul><li></ul></li></ul><li><a href="https&#x3a;&#x2F;&#x2F;www&#x2e;researchgate&#x2e;net&#x2F;post&#x2F;Which&#x5f;distance&#x5f;measure&#x5f;in&#x5f;k&#x2d;means&#x5f;clustering&#x5f;do&#x5f;you&#x5f;suggest">https:&#x2F;&#x2F;www.researchgate.net&#x2F;post&#x2F;Which_distance_measure_in_k-means_clustering_do_you_suggest</a></li><li>* discussion of distance measurements for K-means on Stack Overflow:&nbsp;</li><li>typically, the K-means algorithm determines the distance between an object and its cluster centroid by Euclidean distance measure.&nbsp;</li><li>K-Means <em>is implicitly based</em> on pairwise <em>Euclidean</em> distances b&#x2F;w data points, because <strong>the sum of squared deviations from centroid is equal to the sum of pairwise squared Euclidean distances divided by the number of points</strong>. The term &quot;centroid&quot; is itself from Euclidean geometry. It is multivariate mean in euclidean space. <a href="https&#x3a;&#x2F;&#x2F;stats&#x2e;stackexchange&#x2e;com&#x2F;questions&#x2F;81481&#x2F;why&#x2d;does&#x2d;k&#x2d;means&#x2d;clustering&#x2d;algorithm&#x2d;use&#x2d;only&#x2d;euclidean&#x2d;distance&#x2d;metric">https:&#x2F;&#x2F;stats.stackexchange.com&#x2F;questions&#x2F;81481&#x2F;why-does-k-means-clustering-algorithm-use-only-euclidean-distance-metric</a></li><li>* &quot;K-means for distance matrix&quot; implementation: <a href="https&#x3a;&#x2F;&#x2F;stats&#x2e;stackexchange&#x2e;com&#x2F;questions&#x2F;32925&#x2F;perform&#x2d;k&#x2d;means&#x2d;or&#x2d;its&#x2d;close&#x2d;kin&#x2d;clustering&#x2d;with&#x2d;only&#x2d;a&#x2d;distance&#x2d;matrix&#x2d;not&#x2d;p">https:&#x2F;&#x2F;stats.stackexchange.com&#x2F;questions&#x2F;32925&#x2F;perform-k-means-or-its-close-kin-clustering-with-only-a-distance-matrix-not-p</a></li><li></ul></li></ul><li>* <strong><em>center &#x2F; centroid</em></strong></li><li></li><li>* <strong>error&#x2F;loss</strong>&nbsp;<ul class="indent"><li>* describes the deviation (error) of the model&#x27;s prediction from the expected result, used in supervised learning systems (e.g. deep learning &amp; regression) where an expected output is known --- similar in some ways to the way euclidean distance is used in K-means to judge the quality of clusters</ul><li>* <strong>dimensionality reduction</strong><ul class="indent"><li>* <strong><em>projection</em></strong><ul class="indent"><li>* particularly important for visualization</li><li>* 3D projection space?<ul class="indent"><li>(<a href="https&#x3a;&#x2F;&#x2F;ai&#x2e;googleblog&#x2e;com&#x2F;2018&#x2F;06&#x2F;realtime&#x2d;tsne&#x2d;visualizations&#x2d;with&#x2e;html&#x29;">https:&#x2F;&#x2F;ai.googleblog.com&#x2F;2018&#x2F;06&#x2F;realtime-tsne-visualizations-with.html)</a></li><li>(<a href="https&#x3a;&#x2F;&#x2F;ai&#x2e;googleblog&#x2e;com&#x2F;2016&#x2F;12&#x2F;open&#x2d;sourcing&#x2d;embedding&#x2d;projector&#x2d;tool&#x2e;html&#x29;">https:&#x2F;&#x2F;ai.googleblog.com&#x2F;2016&#x2F;12&#x2F;open-sourcing-embedding-projector-tool.html)</a></ul></li></ul><li>* <strong><em>compression</em></strong><ul class="indent"><li>* many ML systems are implicit &quot;dimensionality reducers&quot; - they reduce the amount of information in a high-dimensional dataset to salient characteristics, which could be as few as a single dimension (such as a classifier with a single output)</li><li>* autoencoders as compression&#x2F;dimensionality reducers: see (PCA vs Autoencoders for dimensionality reduction: <a href="https&#x3a;&#x2F;&#x2F;www&#x2e;r&#x2d;bloggers&#x2e;com&#x2F;pca&#x2d;vs&#x2d;autoencoders&#x2d;for&#x2d;dimensionality&#x2d;reduction&#x2F;&#x29;">https:&#x2F;&#x2F;www.r-bloggers.com&#x2F;pca-vs-autoencoders-for-dimensionality-reduction&#x2F;)</a></ul><li>* principle component analysis (PCA)</li><li></li><li></li><li><strong><em>Interesting further reading:</em></strong></li><li>* A general article on K-means focused on developing an understanding of the algorithm: <a href="https&#x3a;&#x2F;&#x2F;macwright&#x2e;org&#x2F;2012&#x2F;09&#x2F;16&#x2F;k&#x2d;means&#x2e;html">https:&#x2F;&#x2F;macwright.org&#x2F;2012&#x2F;09&#x2F;16&#x2F;k-means.html</a></li><li>* Kmeans++ (an improved Kmeans algorithm with additional step for choosing good starting centroids) <a href="https&#x3a;&#x2F;&#x2F;en&#x2e;wikipedia&#x2e;org&#x2F;wiki&#x2F;K&#x2d;means&#x25;2B&#x25;2B">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;K-means%2B%2B</a></li><li>* In-depth investigation of K-means on google CoLab with interactive python code&nbsp; <a href="https&#x3a;&#x2F;&#x2F;colab&#x2e;research&#x2e;google&#x2e;com&#x2F;github&#x2F;jakevdp&#x2F;PythonDataScienceHandbook&#x2F;blob&#x2F;master&#x2F;notebooks&#x2F;05&#x2e;11&#x2d;K&#x2d;Means&#x2e;ipynb">https:&#x2F;&#x2F;colab.research.google.com&#x2F;github&#x2F;jakevdp&#x2F;PythonDataScienceHandbook&#x2F;blob&#x2F;master&#x2F;notebooks&#x2F;05.11-K-Means.ipynb</a></li><li></li><li><strong><em>Updates from Whatps app:</em></strong></li><li>K-nearest Neighbor looks like another really good algorithm in the same sense as K-means ~ very widely used, simple enough to be able to break down and understand step by step: <a href="https&#x3a;&#x2F;&#x2F;blog&#x2e;usejournal&#x2e;com&#x2F;a&#x2d;quick&#x2d;introduction&#x2d;to&#x2d;k&#x2d;nearest&#x2d;neighbors&#x2d;algorithm&#x2d;62214cea29c7">https:&#x2F;&#x2F;blog.usejournal.com&#x2F;a-quick-introduction-to-k-nearest-neighbors-algorithm-62214cea29c7</a></li><li>And probably even more useful in the short-term and for our Aarhus workshop, this cheat-sheet for all the algorithms inside scikit-learn: <a href="https&#x3a;&#x2F;&#x2F;scikit&#x2d;learn&#x2e;org&#x2F;stable&#x2F;tutorial&#x2F;machine&#x5f;learning&#x5f;map&#x2F;">https:&#x2F;&#x2F;scikit-learn.org&#x2F;stable&#x2F;tutorial&#x2F;machine_learning_map&#x2F;</a></li><li>Also, k-nearest neighbor (kNN) depends heavily on Euclidean distance <a href="https&#x3a;&#x2F;&#x2F;miro&#x2e;medium&#x2e;com&#x2F;max&#x2F;1300&#x2F;0">https:&#x2F;&#x2F;miro.medium.com&#x2F;max&#x2F;1300&#x2F;0</a>*Sk18h9op6uK9EpT8</li><li></ul></li></ul>&nbsp;* select terminologies: from anatomy and popular machine learning culture &#8212; where bias enters &#8212; prevalent ontologic system of knowledge (<a href="https&#x3a;&#x2F;&#x2F;pair&#x2e;withgoogle&#x2e;com&#x2F;glossary&#x2F;">https:&#x2F;&#x2F;pair.withgoogle.com&#x2F;glossary&#x2F;</a> )<br><br><ul class="indent"><li><ul class="indent"><li><strong>Measurements and distances:</strong></ul></li></ul><br><ul class="indent"><li><ul class="indent"><li>Unit&nbsp;&nbsp;&nbsp; Description&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</li><li>cm&nbsp;&nbsp;&nbsp; centimeters&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</li><li>mm&nbsp;&nbsp;&nbsp; millimeters&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</li><li>in&nbsp;&nbsp;&nbsp; inches (1in = 96px = 2.54cm)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</li><li>px *&nbsp;&nbsp;&nbsp; pixels (1px = 1&#x2F;96th of 1in)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</li><li>pt&nbsp;&nbsp;&nbsp; points (1pt = 1&#x2F;72 of 1in)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</li><li>pc&nbsp;&nbsp;&nbsp; picas (1pc = 12 pt)&nbsp;&nbsp;&nbsp;&nbsp;</li><li></li><li>link: <a href="https&#x3a;&#x2F;&#x2F;www&#x2e;w3schools&#x2e;com&#x2F;css&#x2F;css&#x5f;units&#x2e;asp">https:&#x2F;&#x2F;www.w3schools.com&#x2F;css&#x2F;css_units.asp</a>&nbsp;</li><li>also interesting: <a href="https&#x3a;&#x2F;&#x2F;en&#x2e;wikipedia&#x2e;org&#x2F;wiki&#x2F;History&#x5f;of&#x5f;measurement">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;History_of_measurement</a></li><li></li><li>converters:</li><li><a href="https&#x3a;&#x2F;&#x2F;www&#x2e;w3schools&#x2e;com&#x2F;howto&#x2F;howto&#x5f;js&#x5f;length&#x5f;converter&#x2e;asp">https:&#x2F;&#x2F;www.w3schools.com&#x2F;howto&#x2F;howto_js_length_converter.asp</a></li><li>ScanCalc - a small JavaScript utility to convert between centimeters (cm), pixels and dots&#x2F;inch (dpi): <a href="https&#x3a;&#x2F;&#x2F;gist&#x2e;github&#x2e;com&#x2F;soren&#x2F;3058490">https:&#x2F;&#x2F;gist.github.com&#x2F;soren&#x2F;3058490</a></li><li>J.Query: <a href="https&#x3a;&#x2F;&#x2F;codepen&#x2e;io&#x2F;gabrieleromanato&#x2F;pen&#x2F;CuviB">https:&#x2F;&#x2F;codepen.io&#x2F;gabrieleromanato&#x2F;pen&#x2F;CuviB</a><ul class="indent"><li></li><li></ul><li><strong>+ TO DO:</strong></ul></li></ul><s>&nbsp;&nbsp;&nbsp; * which dataset to give to workshop&nbsp;</s><br><s>&nbsp;&nbsp;&nbsp; * participants and revise the workshop</s><br><s>&nbsp;&nbsp;&nbsp; * rehearsal performance sonification;</s><br><s>&nbsp;&nbsp;&nbsp; * test wi fi or local ...;</s><br><s>&nbsp;&nbsp;&nbsp; * select and print examples: reduction of the body (to lower dimensions) to something understandable; computable...</s><br><br><ul class="indent"><li><ul class="indent"><li><strong><em>Dev todo:</em></strong></li><li>* further develop the theatre<ul class="indent"><li>* projections &amp; dimensionality reduction of catalog into a 2D space (maybe 3D space)</li><li>* projections of the clustering &#8212; how the visuals aspects can be explored;<ul class="indent"><li>refs.: <a href="https&#x3a;&#x2F;&#x2F;archiv&#x2e;kunsthalle&#x2d;bern&#x2e;ch&#x2F;en&#x2F;overview">https:&#x2F;&#x2F;archiv.kunsthalle-bern.ch&#x2F;en&#x2F;overview</a><ul class="indent"><li><ul class="indent"><li><ul class="indent"><li><a href="http&#x3a;&#x2F;&#x2F;groups&#x2e;csail&#x2e;mit&#x2e;edu&#x2F;vision&#x2F;TinyImages&#x2F;">http:&#x2F;&#x2F;groups.csail.mit.edu&#x2F;vision&#x2F;TinyImages&#x2F;</a></li><li><a href="https&#x3a;&#x2F;&#x2F;stuff&#x2e;maydayrooms&#x2e;org&#x2F;documents&#x2F;GVI">https:&#x2F;&#x2F;stuff.maydayrooms.org&#x2F;documents&#x2F;GVI</a></ul></li></ul></li></ul></li></ul></li></ul><li><strong>More todo:</strong><ul class="indent"><li>* make a presentation for the workshop &#8212; &gt; see the file &quot;workshop_presentation.html&quot;</li><li>* create a sepparate pad to share links and notes;</li><li>* test &amp; retest OSC connections between sound &amp; browser &#8212; together;</ul></li></ul></li></ul><br>- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -&nbsp;<br><br><strong>* Draft workshop for Aarhus + presentation;&nbsp;</strong><br><ul class="indent"><li><ul class="indent"><li><ul class="indent"><li>* two themes:<ul class="indent"><li><strong>* concepts on distance</strong> in machine learning and anatomy. what is a unit of anatomical distance? what different topologies of geometries; directionality could we accomodate? Position and orientation.&nbsp;</li><li>distance is the moment of judjement.</li><li><strong>* dimensionality reduction:</strong> we have 72 tags&#x2F;dimensions and we reduce to 2D (x+y) euclidean distance always reduces to one numer (distance from the entrance to the centroid)</ul></li></ul></li></ul></li></ul><br><strong>&nbsp;&nbsp;&nbsp; 30min:</strong> intro who we are; explain the project; why anatomy; why ML;&nbsp;<br>&nbsp;&nbsp;&nbsp; <strong>2.15</strong> hour: exercise<br><ul class="indent"><li><ul class="indent"><li><ul class="indent"><li><strong>15min)</strong> on the floor exercise: <a href="https&#x3a;&#x2F;&#x2F;github&#x2e;com&#x2F;anatomiesofintelligence&#x2F;anatomiesofintelligence&#x2e;github&#x2e;io&#x2F;blob&#x2F;master&#x2F;anatomies&#x5f;exercise&#x2e;md">https:&#x2F;&#x2F;github.com&#x2F;anatomiesofintelligence&#x2F;anatomiesofintelligence.github.io&#x2F;blob&#x2F;master&#x2F;anatomies_exercise.md</a>;</li><li></li><li><strong>30min)</strong> introduce ML; distances + dimensionality reduction. K-means as focus: first sudo code; and then we read our own algorithm; <a href="https&#x3a;&#x2F;&#x2F;github&#x2e;com&#x2F;anatomiesofintelligence&#x2F;anatomiesofintelligence&#x2e;github&#x2e;io&#x2F;blob&#x2F;master&#x2F;workshop&#x5f;presentation&#x2e;html">https:&#x2F;&#x2F;github.com&#x2F;anatomiesofintelligence&#x2F;anatomiesofintelligence.github.io&#x2F;blob&#x2F;master&#x2F;workshop_presentation.html</a>&nbsp;</li><li></li><li><strong>30 min)</strong> catalog demo and collective reading of the clustering algorithm; explain the concepts of distance and dimentionality reduction (mainly necessary for vizualization; though essentialy this algorithms are already reducing dimensionalities). &#8212; &gt; &quot;help()&quot;</li><li><ul class="indent"><li>Demo catalogue and algorithm:</li><li><strong>catalog.cluster(CLUSTERS, MEASUREMENT, cut, ITERATIONS, resultfunc, BREAKPOINTS, osc, console.log);</strong></li><li>catalog.cluster(2, Measures.euclidean, CUT, 3 , resultfunc, osc, console.log)</li><li><ul class="indent"><li><ul class="indent"><li>CLUSTER = 2</li><li>MEASUREMENT = Measures.euclidean</li><li>CUT = [&quot;anatomy&quot;, &quot;theatre&quot;, &quot;actors&quot;]</li><li>ITERATIONS = 3</ul></li></ul></li></ul></li></ul></li></ul></li></ul><br><ul class="indent"><li><ul class="indent"><li><ul class="indent"><li><strong>1hour)</strong> exercise IRL clustering interface:&nbsp;<ul class="indent"><li><strong>30 min)</strong> in groups clustering: 20 or more entries in their dataset &#8212; toy dataset (MNIST &#x2F; image dataset)</li><li></li><li>in groups, briefly analize and discuss your dataset; then follow the four main tasks bellow:</li><li><ul class="indent"><li><strong>* distance</strong> (or the concept of difference);<ul class="indent"><li><ul class="indent"><li>How do we deal with temporality? (there is a before and after;)</li><li>Choose a measurement system. Discuss notion a round distance (idea of difference?);</li><li>How do we deal with temporality? (there is a before and after;)&nbsp;</li><li>What measurements and distances could be used?&nbsp;</li><li>Consider existing methods, but also scales and orientations for observation, <strong><em>affective response</em></strong> &amp; affinity.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</li><li>Questions:</li><li>is your notion of ditance multi-dimensional?</li><li>what are its dimensions?</li><li>collect examples and ideas around the notion of &quot;distances&quot;; which ones to consider?&nbsp;</li><li>measurement systems that are used in learning algorithms (for eg.: the euclidean is a popular one; cost and error functions; measures for knowing if you are converging; cross entropy &#8212; decides if the algorythm is learning or not); explore alternative distance measurements for example inspired in anatomical practices or in other systems&#x2F; conventions (cm..) &#8212; option to leave for workshop brainstroming;</li><li></ul></li></ul><li><strong>* tagging and weights</strong> (give values to data samples);</li><li></li><li><strong>* representation</strong> of the knowledge system &#x2F; communicate the process and results<ul class="indent"><li>how to visualize the clustering?</li><li>consider dimensionality reduction (in each what preserves and what is left out);<ul class="indent"><li>*different layers:<ul class="indent"><li>* from tags (processual happening on the data collection);&nbsp;</li><li>* projections (vizualization);</li><li>* sonification; which other senses can take part?</li><li></ul></li></ul></li></ul><li><strong>* cluster:</strong> execute k-means and document the results;<ul class="indent"><li>catalog.cluster(2, Measures.euclidean, CUT, 3 , resultfunc, osc, console.log)</li><li>optional: Use the console&#x2F;javascript api as an observational tool &lt;-- provide commands catalog.cluster(3, Measures.euclidean, [&quot;model&quot;, &quot;aesthesis&quot;, &quot;categorization&quot;, &quot;body&quot;], 10, resultfunc, false) <a href="https&#x3a;&#x2F;&#x2F;anatomiesofintelligence&#x2e;github&#x2e;io&#x2F;theatre&#x2F;kmeans">https:&#x2F;&#x2F;anatomiesofintelligence.github.io&#x2F;theatre&#x2F;kmeans</a></ul></li></ul></li></ul></li></ul></li></ul><li><ul class="indent"><li><ul class="indent"><li><ul class="indent"><li><strong>30min</strong>) optional: experiment the process with another dataset &#x2F; with different measurement systems; parameters; define a another cluster;...;&nbsp;</li><li>Analyze the algorithm; further discuss &#x2F; make a list of potential entry points for performativity, presentation, critical intervention, aesthetic intervention within this algorithm.&nbsp;</li><li></ul></li></ul></li></ul><li><strong>15min:</strong> break&nbsp;</li><li><strong>30min:</strong> group presenations&nbsp;</li><li><strong>30min:</strong> wrapping up and&nbsp;<ul class="indent"><li><ul class="indent"><li><ul class="indent"><li></ul></li></ul></li></ul></li></ul>- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -&nbsp;<br><br>* near future goals<br><ul class="indent"><li><ul class="indent"><li><ul class="indent"><li><ul class="indent"><li>* animate the clustering?&nbsp;</li><li>* grow the dataset:<ul class="indent"><li><ul class="indent"><li>** should we set a clear &#x27;theme&#x27; for the new entrances? for example: hands &#x2F; writing or focus on anatomy &#x2F; ML?</li><li>(on writing &#x2F; gesture: <a href="http&#x3a;&#x2F;&#x2F;reader&#x2e;lgru&#x2e;net&#x2F;texts&#x2F;gesture&#x2d;of&#x2d;writing&#x2F;">http:&#x2F;&#x2F;reader.lgru.net&#x2F;texts&#x2F;gesture-of-writing&#x2F;</a>&nbsp;</li><li>on cutting &#x2F; slices: <a href="https&#x3a;&#x2F;&#x2F;possiblebodies&#x2e;constantvzw&#x2e;org&#x2F;inventory&#x2F;&#x3f;069">https:&#x2F;&#x2F;possiblebodies.constantvzw.org&#x2F;inventory&#x2F;?069</a> )</li><li>&#8220;Knowledge is not made for understanding, it is made for cutting.&#8221; Michel Foucault, Language, Counter-Memory</li><li></ul></li></ul></li></ul></li></ul></li></ul><li>* also check our github project space &#8212; interesting material additions &#8212; should we set a clear &#x27;theme&#x27; for the new entrances?</li><li></ul>&nbsp;&nbsp;&nbsp; * thoughs on movement in performance settings: com-&#x27;posing&#x27; &#x2F; &quot;stillness acts&quot; &#x2F; (projection of code on human fabric)<br><ul class="indent"><li>&nbsp;&nbsp;&nbsp; * notions of distances &#x2F; and hibridity of measurement systems to explore here.</li><li></ul>&nbsp;&nbsp;&nbsp; * should we add a license to our github repo? - explicitly choose one that is open source, etc?<br><ul class="indent"><li><ul class="indent"><li><ul class="indent"><li><ul class="indent"><li></ul></li></ul></li></ul><li>* Thoughts on our ctalogue format; data vizualization; metaphors; interface and skeumorphic design:</li><li></ul>From the book Plain Text: the poetics of computation by Dennis Tenen:<br><ul class="indent"><li><ul class="indent"><li><ul class="indent"><li><ul class="indent"><li><ul class="indent"><li>* &quot;programming language bridge the passage between bodies, archives and screens..&quot;</li><li>* &quot;Because metaphor theory influenced interface design historically, it can also help diagnose modes of metaphoric failure. How do metaphors break and what happens to zombie-like dead metaphors, empty of sense yet functional in ways that no longer honor the initial contract beteen incongruent logics and physicalites.&quot; &#x2F; &quot;A metaphor dies in the sense of being overused, but it dies also in another snese for nor being used at all.&quot; &#x2F; &quot;with these comment s on broken and dead metaphors in mind. I return to computer screens and ask, How do interface metaphors live or die by these definitions?&quot; pp.32 + 34-35</li><li>* &quot;of a gesture as a translation into words and the unerstanding of words as a translation into gestures.&quot; pp. 74</ul></li></ul></li></ul></li></ul></li></ul><br>From Awkward Gestures (Femke Snelting)<br><ul class="indent"><li><ul class="indent"><li><ul class="indent"><li><ul class="indent"><li><ul class="indent"><li>Awkward gesturesNot unlike Zeno&#x27;s experience, it is difficult to stay in motion when the machinery comes to the foreground.Anyone who has seen a designer at work, knows that the self-assured agility with which a layout is done orhow the tension of a digital curve is determined, leaves little or no room for questions about the nature of theunderlying processes. Taking doubt into account implies breaking with the natural &#x27;flow&#x27; of things andaccepting the hitches that aren&#x27;t always that easy to deal with. It is in this way we have started to understandthe importance of performing our practice publicly because it brings out unusual gestures that break with theappeasing elegance of the typical self-assured designer who has everything sorted. <a href="http&#x3a;&#x2F;&#x2F;ospublish&#x2e;constantvzw&#x2e;org&#x2F;blog&#x2F;wp&#x2d;content&#x2F;uploads&#x2F;awkward&#x5f;gestures&#x2e;pdf">http:&#x2F;&#x2F;ospublish.constantvzw.org&#x2F;blog&#x2F;wp-content&#x2F;uploads&#x2F;awkward_gestures.pdf</a></li><li></ul></li></ul></li></ul></li></ul></li></ul>From Possible Bodies:<br><ul class="indent"><li><ul class="indent"><li><ul class="indent"><li><ul class="indent"><li>* on formats:<ul class="indent"><li>&quot;The word &#8220;tract&#8221; offers a different, yet apt, description for the form and content of Possible Bodies&#8217; inventory:&nbsp;<ul class="indent"><li>1. An area or expanse.&nbsp;</li><li>2. A series of connected body organs, as in the digestive tract.</li><li>3. A small booklet such as a pamphlet, often for promotional or informational uses.&nbsp;</li><li>4. A brief treatise or discourse on a subject.&nbsp;</li><li>5. A commentator&#x27;s view or perspective on a subject.&nbsp;</li><li>6. Continued or protracted duration, length, extent.&nbsp;</ul><li>See: <a href="https&#x3a;&#x2F;&#x2F;en&#x2e;wiktionary&#x2e;org&#x2F;wiki&#x2F;tract">https:&#x2F;&#x2F;en.wiktionary.org&#x2F;wiki&#x2F;tract</a>.</ul><li>* on bodies:<ul class="indent"><li>Well, when we say &#8220;body&#8221; it&#8217;s always either in quotation marks or preceded by &#8220;so called&#8221; because part of the work is about really insisting on the political fiction of the &#8220;body&#8221;. Especially in the contact with scanning, modelling, and rendering technologies, it&#8217;s very important to not essentialise the &#8220;body&#8221;&#8212;neither as a unit nor as a human entity. In these environments, the problems that arise when isolating &#8220;body&#8221; and&nbsp; object, and to treat them as entities without agency, might be similar. <a href="http&#x3a;&#x2F;&#x2F;sink&#x2e;sexy&#x2F;texts&#x2F;rendermegrey&#x2F;">http:&#x2F;&#x2F;sink.sexy&#x2F;texts&#x2F;rendermegrey&#x2F;</a></ul></li></ul></li></ul></li></ul></li></ul><br><br><strong><u>Aug 27 &#x2F;&#x2F; MAGDA AARHUS&nbsp;</u></strong><br><br><strong>&gt;&gt;&gt;</strong> 13-14th Dec&nbsp;<br><br><strong>&gt;&gt;&gt; Aarhus Team:</strong> Magda; Winnie Soon; Pablo Gonzalez. Wiki: <a href="http&#x3a;&#x2F;&#x2F;softwarestudies&#x2e;projects&#x2e;cavi&#x2e;au&#x2e;dk&#x2F;index&#x2e;php&#x2F;NN&#x5f;Cluster">http:&#x2F;&#x2F;softwarestudies.projects.cavi.au.dk&#x2F;index.php&#x2F;NN_Cluster</a> &#8212; what are non-heterogeniuous ways of studying ML? Methods that investigate ML that emerge from artistic research.&nbsp;<br><br><strong>&gt;&gt;&gt;</strong> <strong>Workshop</strong> - 4hours - (Colleagues; PhD; Pos-Docs) &#8212; max.20 ppl.&nbsp;<br><strong>&gt; Exercise:</strong> collect data; statistical ontology. Does it represent the data? Critical views on annotation.&nbsp;<br><ul class="indent"><li>&gt; Jupiter notebooks; python script on the shell; or JS locally on the browser.</li><li>&gt; Examining the notion of distance (beyond euclidean) &#8212; thinking of different ways of reading relations (different directios; flows; explode the idea of distance and explore the vocabularies that makes us experience and perceive them otherwise).</li><li></ul><strong>&gt;&gt;&gt; Public Lecture</strong> (for everyone) - 1h (performance and Q&amp;A) &#8212; catalogue thinking and demo &#x2F; stage.<br><br><strong>&gt; Field trip: </strong>medical &#x2F; anatomy and biologic systems research center;<br><br><br><strong><em><u>15 Oct, 2019 ~~~ Jon meeting with Harrison Pim @ Wellcome Collection</u></em></strong><br><br>Harrison points to an artist Refik Anadol (has a show now in new york called Machine Hallucination?). Refik has a project&#x2F;work juxtaposing architectural drawings and structures with AI&#x2F;ML&#x2F;Data architectures.<br><br><a href="https&#x3a;&#x2F;&#x2F;www&#x2e;designboom&#x2e;com&#x2F;art&#x2F;refik&#x2d;anadol&#x2d;machine&#x2d;hallucination&#x2d;artechouse&#x2d;chelsea&#x2d;09&#x2d;11&#x2d;2019&#x2F;">https:&#x2F;&#x2F;www.designboom.com&#x2F;art&#x2F;refik-anadol-machine-hallucination-artechouse-chelsea-09-11-2019&#x2F;</a><br><a href="https&#x3a;&#x2F;&#x2F;www&#x2e;invidio&#x2e;us&#x2F;watch&#x3f;v&#x3d;8et1aGdI0HU">https:&#x2F;&#x2F;www.invidio.us&#x2F;watch?v=8et1aGdI0HU</a><br><br><br><strong><em><u>About the Wellcome collection:</u></em></strong><br><br>There are really two collections<br>1. What Henry collected, a &quot;cabinet of curiosities&quot;<br>2. What was collected after by the Wellcome trust<br><br>Much of the collection&#x27;s objects are housed at the London Science Museum, which is better equipped to care for and exhibit such objects.<br>Wellcome itself only keeps objects that tell human stories, in a more ethnographic way, or even diving deeper into personal&#x2F;individual narratives.<br>Wellcome tries to position its value as an institution in telling these human stories (another reason for many of the instruments and scientific curiosities being kept at the science museum)<br><br>The Wellcome Library is the most consistent part of the collection, and definitely the most coherent in theme and purpose, as opposed to the object collection which is in Harrison&#x27;s words, &quot;a bit mad&quot;. Harrison&#x27;s role at Wellcome is to use ML and other data analysis algorithms to make sense of this diverse and at times chaotic collection. And to create a sensible searching system for the archive itself.<br><br><a href="https&#x3a;&#x2F;&#x2F;wellcomelibrary&#x2e;org&#x2F;collections&#x2F;about&#x2d;the&#x2d;collections&#x2F;archives&#x2d;and&#x2d;manuscripts&#x2F;">https:&#x2F;&#x2F;wellcomelibrary.org&#x2F;collections&#x2F;about-the-collections&#x2F;archives-and-manuscripts&#x2F;</a><br><br>The beta version of his work is here: <a href="https&#x3a;&#x2F;&#x2F;wellcomecollection&#x2e;org&#x2F;works&#x2F;progress">https:&#x2F;&#x2F;wellcomecollection.org&#x2F;works&#x2F;progress</a><br><br>Most of what is available is images, there are sound and film items in the collection, but Harrison has not seen a critical mass of them to be able to do useful ML search with them.&nbsp;<br><br>There are currently two public APIs for the collection:<br>1. Wellcome API &gt;&gt; searches returning metadata<br>2. Image API &gt;&gt; data api using a standard protocol the International Image Interoperability Framework <a href="https&#x3a;&#x2F;&#x2F;iiif&#x2e;si&#x2e;edu&#x2F;">https:&#x2F;&#x2F;iiif.si.edu&#x2F;</a><br><br>I told him we would be interested in doing some text search&#x2F;scraping through the Wellcome library. He said he could help us with that and would be really happy to work with us on a practical initiative so he can also learn how more people want to use the collection.<br><br>I expressed interest in the culture and context surrounding the collection activities of Wellcome, Harrison recommended checking out the WELLCOME ARCHIVE<br>which is an archive about the Wellcome trust itself, containing meta-knowledge about the Wellcome collection&#x27;s culture &amp; context - criteria for knowledge gathering &amp; classification<br><br><a href="https&#x3a;&#x2F;&#x2F;wellcomelibrary&#x2e;org&#x2F;what&#x2d;we&#x2d;do&#x2F;history&#x2d;of&#x2d;wellcome&#x2d;library&#x2F;researching&#x2d;wellcome&#x2d;work&#x2F;">https:&#x2F;&#x2F;wellcomelibrary.org&#x2F;what-we-do&#x2F;history-of-wellcome-library&#x2F;researching-wellcome-work&#x2F;</a><br><br><br>Currently there are multiple catalogs, and he is trying to wrap them up into a unified system, but to do so &quot;respectfully&quot;<br>(this gets into some really interesting parts of how data is treated at Wellcome) --- what does it mean to respectfully attempt to universalize pluralist knowledge areas?<br><br>Also interesting in this case is that Harrison (describing himself as &quot;the organizer&quot;) ~~~ does not have domain over the data itself &gt;&gt; that role belongs to the collectors who come from different fields.<br><br>Sometimes the universal data ontology that he is trying to create doesn&#x27;t fit certain fields of knowledge, and a field may be erased&#x2F;excluded because it doesn&#x27;t fit the data ontology. The goal of his system is that &quot;everything is discoverable in the same way with the same weight&quot; &gt;&gt; he is also looking at the possibility of using ML to generate its own categories and fields, so that these relationships aren&#x27;t lost. He is also trying to develop a clever NLP system to be able to cluster items by &quot;subject&quot; in this same sense.<br><br>He asks for my commentary&#x2F;opinion on AI: my belief is that software design&#x2F;engineering is moving from an &quot;architecture&quot; mode to one of &quot;shepherding&quot;<br><br><br><em><u>Harrison has a full-time position and he&#x27;s going to be working for a while on this project</u></em><br>he really appreciates talking to an artist&#x2F;humanities person who also gets the ML side of things...<br><br>He suggests that next time, meet with others within the organization also working with data, collection, archiving, and knowledge structuring<br><br>&gt;&gt;future projects?<br>* like with the Leiden collection, a project focused on Wellcome&#x27;s history, context, people and cultural&#x2F;espitemological values<br>* text scraping &#x2F; working with the Wellcome api<br>* continued discussion with Harrison, maybe apply for funding with V2&#x2F;Wellcome<br><br>[pre-meeting notes]<br>* meeting points for Welcome Collection:<br><ul class="indent"><li><ul class="indent"><li><ul class="indent"><li><ul class="indent"><li>* intersection of machine learning and W.C.</li><li>* how to best use the dataset?&nbsp;<ul class="indent"><li><ul class="indent"><li>** what there collection focus on?</li><li>** what machine learning or other methods do they use for making sense of the archive?</li><li>** how do they create an anthology.</ul></li></ul></li></ul></li></ul></li></ul></li></ul><br>interesting beta collection search database: <a href="https&#x3a;&#x2F;&#x2F;wellcomecollection&#x2e;org&#x2F;works&#x2F;progress">https:&#x2F;&#x2F;wellcomecollection.org&#x2F;works&#x2F;progress</a><br>and code: <a href="https&#x3a;&#x2F;&#x2F;github&#x2e;com&#x2F;wellcometrust&#x2F;catalogue&#x2F;blob&#x2F;d1b4229f6e85c09dd7e5b0c94cffc898d11e23b9&#x2F;api&#x2F;api&#x2F;src&#x2F;main&#x2F;scala&#x2F;uk&#x2F;ac&#x2F;wellcome&#x2F;platform&#x2F;api&#x2F;models&#x2F;WorkQuery&#x2e;scala&#x23;L15&#x2d;L28">https:&#x2F;&#x2F;github.com&#x2F;wellcometrust&#x2F;catalogue&#x2F;blob&#x2F;d1b4229f6e85c09dd7e5b0c94cffc898d11e23b9&#x2F;api&#x2F;api&#x2F;src&#x2F;main&#x2F;scala&#x2F;uk&#x2F;ac&#x2F;wellcome&#x2F;platform&#x2F;api&#x2F;models&#x2F;WorkQuery.scala#L15-L28</a><br><br><br><br><br><strong><u>JUNE 24 &#x2F;&#x2F; PHOTOGRAPHERS GALLERY COMISSION</u></strong><br><br><a href="https&#x3a;&#x2F;&#x2F;thephotographersgallery&#x2e;org&#x2e;uk&#x2F;whats&#x2d;on&#x2F;digital&#x2d;project&#x2F;open&#x2d;call&#x2d;what&#x2d;can&#x2d;you&#x2d;do&#x2d;image&#x2d;dataset">https:&#x2F;&#x2F;thephotographersgallery.org.uk&#x2F;whats-on&#x2F;digital-project&#x2F;open-call-what-can-you-do-image-dataset</a><br><br>Questions:<br>* can we apply as a duo? yes!<br>* what is the deadline for display; The selected works will be exhibited on the Media Wall from March 2020&nbsp;<br><br>Proposal:<br>* Dataset: (1) the creation of a new or speculative photographic dataset, which can be released to the public and shown on the Media Wall;<br>(currently approx-400 words)<br><br>KEYWORDS: machine learning, algorithmic performance, web interfaces, networked infrastructures, computer programming, digital cultures, hybrid languages, data behaviorism, embodiment, movement studies, scores &amp; scripts;&nbsp;<br><br>For our dataset we would like to collect images of hands; starting with a small number collected within our network which will expand from the contribution of the visitors of the Photographers gallery.<br><br>Following our on going research on anatomy and the categorization and modelling of body parts &#8212; the hands play not only a fundamental role in anatomic practices as the first instruments for investigating different organism and &#x27;accessing information&#x27; but also crucial in the formation of writing, type writing; and in general as mechanism for recording information.<br><br>(see reference on tacit knowledge: <a href="https&#x3a;&#x2F;&#x2F;anatomiesofintelligence&#x2e;github&#x2e;io&#x2F;posts&#x2F;2018&#x2d;10&#x2d;29&#x2d;tacit&#x2d;elegant&#x2d;anatomy">https:&#x2F;&#x2F;anatomiesofintelligence.github.io&#x2F;posts&#x2F;2018-10-29-tacit-elegant-anatomy</a> )<br><br>The creation of our own dataset follows our &quot;hands-on&quot; approach to investigating machine learning processes. By collecting and building our own dataset we emphasize the artisanal quality of the process and our quest to closely &quot;observe&quot; the &quot;preparation&quot; of a corpus of data.&nbsp;<br><br>Equaly drawing on our work methology, we aim to focus on a process-based framwork and quest for liveness which led us to the decision of displaying the status of the &#8220;corpus of data&#8221; as the main vizualization material of the Media Wall.&nbsp;<br><br>By projecting in the Media Wall we turn the latter into a shared experience, providing the audience an insight to the evolution of the algorithm, and the possibility to actively participate by contributing with their own &#x27;hands&#x27;.<br><br>Along with the creation of a new dataset we will use a self generating&#x2F; auto-tagging system based on the metadata from the different entries to speculate on possible relations between the material in the dataset. The different tags originated by the algorithm will overlay the images; and create new narrative, stories and histories surrounding the dataset.<br><br><br>[image to 9 screens &#x2F; sketches]<br><br><br>Technical details<br><br>Display a live interface &#x2F; dataset status (HTML5; CSS; JS)<br><br>BACK END:<br><ul class="indent"><li>an interface for uploading the image contribution.</ul>FRONT END:<br><ul class="indent"><li>the vizualization of the most recent contribution and its relation to the whole.</li><li></li><li></ul>The visitor of the museum will witness a growing visual display together with the formation of a complex network agencies &#8212; human and nonhuman. Rethinking modes of &#x27;mediation&#x27;, and the temporalities inherit in such algorithmic processes. And understanding the body as a relational field of interactions, intensities, in constant negotiation with the surrounding environment, technologies and agencies.<br><br>To DO:<br><br>* CV<br>* 3 works: performance; web API&#x2F;interface; sonification;&nbsp;<br>* 500 words proposal (Title: Anatomies of Intelligence: hands-on dataset)<br>* Images: take pictures of hands; show different layout &#x2F; visualisations: most recent hands + tags; clustering;&nbsp;<br>Display alternates from the most recent entries to clustering<br><br><br>* collect new dataset<br>* two interfaces: for uploading dataset material + display interface (&#8216;the status&#8217;&#x2F; tests on clustering using the tagging&#x2F;timeline)<br>* technique: auto-tagging;&nbsp;<br><br><br>COGWEB algorithms, pre K-means Or using k-means to define tags + weights; and then cluster again using self-learned features<br><br>Motif: 18th century metaphor of the collector; doing the God&#8217;s work; businessman; curator; scientist.&nbsp;&nbsp;<br><br>Instructions: black background (or white? ~ maybe easier for people to just grab some paper as a background); one or two hands; up (more vulnerable, also strongly suggests biometrics) or down (perspective of the operator&#x2F;type writer);&nbsp;<br>Commons and copyright issues; terms and. conditions. Open source.<br>QUESTION: what if people upload something other than a hand? how regularly should we check the database?&nbsp;<br><br>Categories<br>Hand Measures<br>Speed of writing<br>Writing tools<br>Languages<br>What is your main writing format (poetry, computer program, excel, python, music notation, text messages...)<br>Weight: how artisenal []&nbsp; mechanic []&nbsp;&nbsp;<br><br>Age&#x2F;gender&#x2F;nationality&#x2F;profession<br><br><br>interface reference ( <a href="http&#x3a;&#x2F;&#x2F;www&#x2e;erg&#x2e;be&#x2F;m&#x2F;&#x23;Bienvenue&#x5f;&#x25;C3&#x25;A0&#x5f;l&#x25;E2&#x25;80&#x25;99erg">http:&#x2F;&#x2F;www.erg.be&#x2F;m&#x2F;#Bienvenue_%C3%A0_l%E2%80%99erg</a> + <a href="https&#x3a;&#x2F;&#x2F;encyclopediedelaparole&#x2e;org&#x2F;fr">https:&#x2F;&#x2F;encyclopediedelaparole.org&#x2F;fr</a> )<br><br>(may be no need to explicitly ref.: tool making &#x2F; Hand morphology <a href="https&#x3a;&#x2F;&#x2F;www&#x2e;ncbi&#x2e;nlm&#x2e;nih&#x2e;gov&#x2F;pmc&#x2F;articles&#x2F;PMC4027422&#x2F;">https:&#x2F;&#x2F;www.ncbi.nlm.nih.gov&#x2F;pmc&#x2F;articles&#x2F;PMC4027422&#x2F;</a> )<br>_________________________________________________________________________________________________________<br><br>Basel Action Points:<br>&nbsp;&nbsp;&nbsp; * finish the about page (Jon)<br>&nbsp;&nbsp;&nbsp; * create a glossary of anatomical descriptors (Joana) here: <a href="https&#x3a;&#x2F;&#x2F;github&#x2e;com&#x2F;anatomiesofintelligence&#x2F;anatomiesofintelligence&#x2e;github&#x2e;io&#x2F;blob&#x2F;master&#x2F;glossary&#x2e;md">https:&#x2F;&#x2F;github.com&#x2F;anatomiesofintelligence&#x2F;anatomiesofintelligence.github.io&#x2F;blob&#x2F;master&#x2F;glossary.md</a><br>&nbsp;&nbsp;&nbsp; * trace a conceptual path for the presentation supported by catalog entries (Joana)&gt; check below the coloured edits<br>&nbsp;&nbsp;&nbsp; * monolog&#x2F;visceral narration for performance, following a K-means clustering (Joana) &gt; tracing the process of the algorithm as a visceral narrative; for example; tags; weights; clusters...here but still in progress: <a href="https&#x3a;&#x2F;&#x2F;github&#x2e;com&#x2F;anatomiesofintelligence&#x2F;anatomiesofintelligence&#x2e;github&#x2e;io&#x2F;blob&#x2F;master&#x2F;narration&#x2e;md">https:&#x2F;&#x2F;github.com&#x2F;anatomiesofintelligence&#x2F;anatomiesofintelligence.github.io&#x2F;blob&#x2F;master&#x2F;narration.md</a><br>&nbsp;&nbsp;&nbsp; * make a new set of exercises focus on location adding the anatomic vocabulary that denotes: proximity; orientation; positioning; direction... (Joana) here: <a href="https&#x3a;&#x2F;&#x2F;github&#x2e;com&#x2F;anatomiesofintelligence&#x2F;anatomiesofintelligence&#x2e;github&#x2e;io&#x2F;blob&#x2F;master&#x2F;anatomies&#x5f;exercise&#x2e;md">https:&#x2F;&#x2F;github.com&#x2F;anatomiesofintelligence&#x2F;anatomiesofintelligence.github.io&#x2F;blob&#x2F;master&#x2F;anatomies_exercise.md</a><br><s>&nbsp;&nbsp;&nbsp; * reply to Shintaro with text for &quot;program&quot; &amp; asking questions about setup&#x2F;presentation (Joana)</s> &gt;&gt;&gt; ask Shintaro for yoga matresses!<br>&nbsp;&nbsp;&nbsp; * visceral qualities of sound &#x2F; sonification of K-means process (Jon sonification of algorithm (via ... webmidi? webaudio?))<br>&nbsp;&nbsp;&nbsp; * (lp) develop more specific&#x2F;useful output from K-means process&gt;console,or visual (Jon)<br>&nbsp;&nbsp;&nbsp; * (lp) check status of weights &amp; tags in entries (Jon)<br><br>Post-Basel Thoughts &amp; Avenues of Inquiry:<br>&nbsp;&nbsp;&nbsp; * Consider a lab-like format for exploration, co-learning &amp; deep dissection of code&#x2F;exercises<br><ul class="indent"><li>&nbsp;&nbsp;&nbsp; * Use as a platform for exploring specific study cases in depth and by writing code, gathering datasets &amp; training models</ul>&nbsp;&nbsp;&nbsp; * Catalog<br><ul class="indent"><li>&nbsp;&nbsp;&nbsp; *source urls should be links<ul class="indent"><li><ul class="indent"><li>*formatting&#x2F;aesthetics?</ul></li></ul></li></ul>&nbsp;&nbsp;&nbsp; * Continued work on K-means demonstration &amp; interface<br><ul class="indent"><li><ul class="indent"><li>* Robust computer-to-computer networking solution</li><li>* Long Goal (practice what we preach): A fully unsupervised process for determining a &quot;statistical ontology&quot; for our research entries<ul class="indent"><li>* self-computing tags &amp; features<ul class="indent"><li>* Word2Vec based text analysis</li><li>* Image Analysis&#x2F;Object Recognition (e.g. via js ML libraries)</li><li>* suggestive tag titles&#x2F;generative naming of things</li><li>* (un)supervised feature learning <a href="https&#x3a;&#x2F;&#x2F;en&#x2e;wikipedia&#x2e;org&#x2F;wiki&#x2F;Feature&#x5f;learning">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Feature_learning</a></li><li></ul><li>* Further explorations of K-means<ul class="indent"><li>* Alternative measures</li><li>* Live visualization of process</li><li>* Alternative clustering algorithms</ul><li>* Public-facing javascript API (accessible via web console) to navigate website</ul></li></ul></li></ul><br><br>General To Do: List:<br><s>&nbsp;&nbsp;&nbsp; &gt; clean the catalogue;</s><br><s>&nbsp;&nbsp;&nbsp; &gt; go through the presentation and workshop;&nbsp;</s><br>&nbsp;&nbsp;&nbsp; &gt; make classification K-means algorithm more transparent on page<br>JR:<br>&nbsp;&nbsp;&nbsp; Performance thinking points:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ~ More integration of sound &amp; categorization process<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ~ sonification of algorithmic steps &#x2F; process<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ~ dramaturgy &amp; roles of performers<br>equipment for performance: 2+ beamers with long cables; projection table; hanging screens; beamer mounts (ceiling, standing); loudspeakers; microphone on stand.<br><br><br><br><br>Text from FB event page:<br><ul class="indent"><li></ul>The anatomical theatre, which paralleled the emergence of the university as the premier learning institute in Europe, has been a time-space where bodies and their organisation became spectacles of scientific knowledge. It informed and disseminated an epistemological shift, introducing classification systems and taxonomies, practices of knowledge collection, as well as a specific understanding of the body as a system reducible to its constituent[standardized] parts.<br><br>Anatomies of Intelligence is an artistic research initiative seeking to make connections between the formats and traditions of anatomical knowledge as a starting point for critical, performative investigations into the &quot;anatomy&quot; of computational learning and prediction processes, data corpora and machine learning models.&nbsp;<br><br><a href="https&#x3a;&#x2F;&#x2F;anatomiesofintelligence&#x2e;github&#x2e;io&#x2F;perform&#x2e;html">https:&#x2F;&#x2F;anatomiesofintelligence.github.io&#x2F;perform.html</a><br><a href="https&#x3a;&#x2F;&#x2F;www&#x2e;ixdm&#x2e;ch&#x2F;re&#x2d;imagining&#x2d;ai&#x2d;pre&#x2d;program&#x2F;">https:&#x2F;&#x2F;www.ixdm.ch&#x2F;re-imagining-ai-pre-program&#x2F;</a><br><br>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _&nbsp;<br><br>Bios:<br><br>Joana Chicau[PT&#x2F;NL]is a graphic designer, coder, researcher &#8212; with a background in dance. Her trans-disciplinary project interweaves web programming languages and environments with choreographic practices. In her practice she researches theintersection of the body with the constructed, designed, programmed environment, aiming at in widening the ways in which digital sciences is presented and made accessible to the public. She has been actively participating and organizing events with performances involving multi-location collaborative coding, algorithmic improvisation, open discussions on gender equality and activism.<br>Web: <a href="http&#x3a;&#x2F;&#x2F;joanachicau&#x2e;com&#x2F;">http:&#x2F;&#x2F;joanachicau.com&#x2F;</a><br><br>Jonathan Reus [US&#x2F;NL] is a musician and artist who explores expanded forms of music-making and improvisational performance through technological artefacts. His practice is cross-disciplinary and research-based, involving open and iterative processes of collaboration with practitioners from across the arts, sciences and humanities. His work tries to confront and challenge the representational capacities of mathematical-logistical systems, algorithms, and infrastructure through a practice of invasive intuition and trust in the diversity of lived experiences.<br>Web: <a href="https&#x3a;&#x2F;&#x2F;jonathanreus&#x2e;com&#x2F;">https:&#x2F;&#x2F;jonathanreus.com&#x2F;</a><br><br>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _&nbsp;<br><br><br><br>PART 1 - intro to people, research project, method, vocabularies,...<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (&#x2F;10min) introduce each individual background and practice;&nbsp;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Joana: <a href="http&#x3a;&#x2F;&#x2F;joanachicau&#x2e;com&#x2F;Media&#x5f;Choreographies&#x2e;html">http:&#x2F;&#x2F;joanachicau.com&#x2F;Media_Choreographies.html</a><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Jonathan: <a href="http&#x3a;&#x2F;&#x2F;jonathanreus&#x2e;com&#x2F;">http:&#x2F;&#x2F;jonathanreus.com&#x2F;</a><br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (&#x2F;10min)&nbsp;<br>&quot;body scan meditation&quot; warm-up &#x2F; embodiment exercise (I often conduct a breathing exercise which creates pathways through the body) &lt;--can this utilize anatomical terminology as well?<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (&#x2F;20min) presentation on our research: &lt;-- presentation traces a path through the catalog, add new entries as needed to facilitate the narrative of the presentation<br><br><strong>dataset</strong>: elegant anatomy book entries as training dataset: <a href="https&#x3a;&#x2F;&#x2F;anatomiesofintelligence&#x2e;github&#x2e;io&#x2F;posts&#x2F;2018&#x2d;10&#x2d;31&#x2d;ML&#x2d;Algolit&#x2d;ElegantAnatomy">https:&#x2F;&#x2F;anatomiesofintelligence.github.io&#x2F;posts&#x2F;2018-10-31-ML-Algolit-ElegantAnatomy</a><br><br>Aesthesis in anatomy. Materiality and elegance in the Eighteenth-Century Leiden Anatomical Collections, Marieke Hendriksen (dissertation: open access, Leiden University): <a href="https&#x3a;&#x2F;&#x2F;openaccess&#x2e;leidenuniv&#x2e;nl&#x2F;handle&#x2F;1887&#x2F;20301">https:&#x2F;&#x2F;openaccess.leidenuniv.nl&#x2F;handle&#x2F;1887&#x2F;20301</a><br><br><strong>method</strong>: concept of aesthesis&#x2F; aesthesia &#x2F; embodiment &#x2F; reliance on the senses &#x2F; performance and performativy: a live&#x2F;embodied ~ but rule-based practice of ontology-making.&nbsp;<br><ul class="indent"><li></li><li>The Concept of Aesthesis</li><li><a href="https&#x3a;&#x2F;&#x2F;anatomiesofintelligence&#x2e;github&#x2e;io&#x2F;posts&#x2F;2018&#x2d;10&#x2d;14&#x2d;aesthesis&#x2d;elegant&#x2d;anatomy">https:&#x2F;&#x2F;anatomiesofintelligence.github.io&#x2F;posts&#x2F;2018-10-14-aesthesis-elegant-anatomy</a></ul><br><ul class="indent"><li>&#8220;Aesthesis in eighteenth-century anatomy was characterized by several factors: gaining knowledge through sensory perception; searching for perfection and elegance; dealing with disgust by either using visual or literary strategies; seeking systems and meanings in the negatives of deformation and pathologies; and a stabilization and categorization of the human body through commodification and decoration.&#8221;</li><li><a href="https&#x3a;&#x2F;&#x2F;anatomiesofintelligence&#x2e;github&#x2e;io&#x2F;posts&#x2F;2018&#x2d;10&#x2d;14&#x2d;aesthesis&#x2d;elegant&#x2d;anatomy">https:&#x2F;&#x2F;anatomiesofintelligence.github.io&#x2F;posts&#x2F;2018-10-14-aesthesis-elegant-anatomy</a></ul><br><ul class="indent"><li>Pp.12 + &#8220;The eighteenth-century Leiden anatomical preparations are the result of a profound eighteenth-century aesthesis which includes both the continuous use of sensory perception as a source of knowledge and a permanent tacit quest for finding and understanding beauty, as well as dealing with the disgusting aspects of anatomy, along with the desire to commodify and objectify the human body.&#8221;</li><li></ul>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; * the process of preparation (artisanal&#x2F;&nbsp; tacit knowledge &#x2F; hands on):<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <a href="https&#x3a;&#x2F;&#x2F;anatomiesofintelligence&#x2e;github&#x2e;io&#x2F;posts&#x2F;2018&#x2d;10&#x2d;29&#x2d;tacit&#x2d;elegant&#x2d;anatomy">https:&#x2F;&#x2F;anatomiesofintelligence.github.io&#x2F;posts&#x2F;2018-10-29-tacit-elegant-anatomy</a><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; On the Agency of Anatomical Preparations&#x2F; collecting (anatomies) &#x2F; as curatorial pracice&nbsp;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; * <a href="https&#x3a;&#x2F;&#x2F;anatomiesofintelligence&#x2e;github&#x2e;io&#x2F;posts&#x2F;2018&#x2d;10&#x2d;16&#x2d;the&#x2d;fate&#x2d;of&#x2d;anatomical&#x2d;collections&#x2d;part3&#x2d;7">https:&#x2F;&#x2F;anatomiesofintelligence.github.io&#x2F;posts&#x2F;2018-10-16-the-fate-of-anatomical-collections-part3-7</a><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Commodification:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; * <a href="https&#x3a;&#x2F;&#x2F;anatomiesofintelligence&#x2e;github&#x2e;io&#x2F;posts&#x2F;2018&#x2d;10&#x2d;29&#x2d;commodification&#x2d;elegant&#x2d;anatomy">https:&#x2F;&#x2F;anatomiesofintelligence.github.io&#x2F;posts&#x2F;2018-10-29-commodification-elegant-anatomy</a><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; An Aesthesis ex-Negativo Emerged<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; * <a href="https&#x3a;&#x2F;&#x2F;anatomiesofintelligence&#x2e;github&#x2e;io&#x2F;posts&#x2F;2018&#x2d;11&#x2d;6&#x2d;aesthesis&#x2d;negativo">https:&#x2F;&#x2F;anatomiesofintelligence.github.io&#x2F;posts&#x2F;2018-11-6-aesthesis-negativo</a><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Freakish Incidents or Devil&#x27;s Work or Unknown Categories &#x2F; Pattern disruption<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; * <a href="https&#x3a;&#x2F;&#x2F;anatomiesofintelligence&#x2e;github&#x2e;io&#x2F;posts&#x2F;2018&#x2d;11&#x2d;6&#x2d;monsters&#x2d;preserved">https:&#x2F;&#x2F;anatomiesofintelligence.github.io&#x2F;posts&#x2F;2018-11-6-monsters-preserved</a><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; * <a href="https&#x3a;&#x2F;&#x2F;anatomiesofintelligence&#x2e;github&#x2e;io&#x2F;posts&#x2F;2018&#x2d;11&#x2d;6&#x2d;monsters&#x2d;unknown">https:&#x2F;&#x2F;anatomiesofintelligence.github.io&#x2F;posts&#x2F;2018-11-6-monsters-unknown</a><br>&nbsp;<br>&nbsp;<br>An ontological shift at the interstice of craft, aesthetics, and knowledge production -&gt; &quot;statistical ontologies&quot; ~~~~~ sorting and optimization rules that can be carried out by a large group:<br>&nbsp;&nbsp;&nbsp;&nbsp;<br><ul class="indent"><li><ul class="indent"><li><ul class="indent"><li>* how do we assess ontological fitness&#x2F;value&#x2F;&quot;cost&quot;&#x2F;artisenal&#x2F;procedural?</li><li>* identifying aesthetics&#x2F;aesthesis&#x2F;bias in the processes used above</li><li>* rethinking categories (corpus&#x2F; gesture&#x2F; modelling&#x2F; systems-of-knowing);</li><li>* methods for reducing subjectivity &amp;&amp; value in doing so</li><li>* links to performance&#x2F;performativity<ul class="indent"><li><ul class="indent"><li></ul></li></ul></li></ul></li></ul></li></ul>(for ref: <a href="https&#x3a;&#x2F;&#x2F;anatomiesofintelligence&#x2e;github&#x2e;io&#x2F;fiber&#x29;">https:&#x2F;&#x2F;anatomiesofintelligence.github.io&#x2F;fiber)</a><br><br><ul class="indent"><li>(&#x2F;10min)</ul>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; collectively inspect the algorithm<br>&gt; <a href="https&#x3a;&#x2F;&#x2F;github&#x2e;com&#x2F;anatomiesofintelligence&#x2F;anatomiesofintelligence&#x2e;github&#x2e;io&#x2F;blob&#x2F;master&#x2F;code&#x2F;lib&#x2F;ai&#x2d;instruments&#x2e;js">https:&#x2F;&#x2F;github.com&#x2F;anatomiesofintelligence&#x2F;anatomiesofintelligence.github.io&#x2F;blob&#x2F;master&#x2F;code&#x2F;lib&#x2F;ai-instruments.js</a><br><br>___________________________________________________________________________________<br>PART TWO<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (30min) activity: strategies for anatomical observation<br><br>in small groups (20&#x2F;4)&nbsp;<br><br><ul class="indent"><li><a href="https&#x3a;&#x2F;&#x2F;anatomiesofintelligence&#x2e;github&#x2e;io&#x2F;theatre&#x2F;kmeans">https:&#x2F;&#x2F;anatomiesofintelligence.github.io&#x2F;theatre&#x2F;kmeans</a></li><li></li><li>&quot;anatomical observation&quot; --&gt;&nbsp;</li><li>01. Use the console&#x2F;javascript api as an observational tool &lt;--&nbsp;</li><li>02. As a group come up with a short paragraph or monologue (s) describing the aesthetics of this algorithm that you observe.&nbsp;</li><li>Consider methods, scales and orientations for observation, <strong><em>affective response</em></strong> &amp; affinity - and how such observations can be performed&#x2F;presented as intimate&#x2F;tacit understanding.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</li><li>03. Further discuss &#x2F; make a list of potential entry points for performativity, presentation, critical intervention, aesthetic intervention within this algorithm.&nbsp;</li><li></ul><br><ul class="indent"><li><ul class="indent"><li><ul class="indent"><li><ul class="indent"><li><ul class="indent"><li><ul class="indent"><li><ul class="indent"><li><ul class="indent"><li><ul class="indent"><li></ul></li></ul></li></ul></li></ul></li></ul></li></ul></li></ul></li></ul></li></ul>catalog.cluster(2, Measures.euclidean, [&#8220;aesthesis&#8221;], 3, resultfunc, osc, console.log)&nbsp;<br><br>&gt;&gt;thoughts from the participants:&nbsp;<br>&gt; straightness of lines; alternative ways to thinking pathways &#8212; more &#x27;organic&#x27;&nbsp;<br>&gt; k-means ballet<br>&gt; the screen is still the primary interface and how to find other ways of interfacing;<br>&gt; different approach to reduction; what is lost?&nbsp;<br>&gt; clusters as creators of ontologies? &#8212; when you state the problem you constrain the process. We create the space of what we get?&nbsp;<br>&gt; epistemic: would another models which is not the k-means would gives different tags?<br>&gt; centrality vs periphery (gaps&#x2F; the unknown) &#8212; k-means monstrousities.<br>&gt; bias vs mis-interpretations; proxies the assumptions that something means something - &gt; source of biases; stting values&#x2F; measuring and interpretations of values. CUT as the formation of biasis.&nbsp;<br>&gt; enlightenment (tacit knowledge vs rationalization) &#8212; &gt; machine learning as epistemological shift in computational systems.&nbsp;<br>&gt; how to bring AI &#x2F; coding processes into a 3D space?&nbsp;<br>&gt; what notions of aethetics are at stake and being generated?&nbsp;<br>&gt; different modes of existence of coded objects; agents collaborating: machines, programs and us &#8212; &gt; not in isolation<br>&gt; using angular instead of euclidean?&nbsp;<br>&gt; other forms of anatomic practices: chinese anatomy (surface level); anatomy japanese (late 19th century - Versalius japanese version of the book); chinese monk illustrating stomach as a waterfall.<br>&gt; Napolis San Martino &#x27;pretrefing&#x27; bodies (chapel);&nbsp;<br><br>&gt;&gt;thoughts &#x2F; notes from conference<br>Dara Blumenthal &quot;Corpus Infinitum&quot; &gt; the body as relational &gt; <a href="https&#x3a;&#x2F;&#x2F;kent&#x2e;academia&#x2e;edu&#x2F;DaraBlumenthal">https:&#x2F;&#x2F;kent.academia.edu&#x2F;DaraBlumenthal</a><br><br>How does she, in the &quot;Feminist AI&quot; project, negotiate this desire to use feminist thinking while still leveraging technologies based on the kind of thinking that she is attempting to challenge? E.G. Wekinator is based on an off-the-shelf ML library, Weka.<br><br>Debate in the UK &quot;The Machinery Question&quot;: a crucial moment in the making of the educational institution of England<br><br>Matteo Pisquilani: the perceptron&#x2F;neural network introduced a topological turn in computation. The paradigm of &quot;computational space&quot; or &quot;self-computing space&quot; ... e.g. cellular automata, he puts neural networks into this &quot;turn&quot; that is different from the Turing Machine-like algorithms. CA remain finite-state algorithms. Zuse attempted to extend CA to the whole universe - the idea of &quot;calculating space&quot; is to concieve of the universe as made up of particles as self-computing actors.&nbsp;<br>--- could he explain futher &#x2F; expand on this idea of a &quot;topological turn&quot; and how is this a &quot;turn&quot; different from a Turing-machine type of understanding of algorithms? Because the computational structure is organized as a graph? What are the stakes of this &quot;turn&quot;? Or is topological? And how is this tied to AI in particular?&nbsp;<br><br>Q: what is the distinction between logic and labor?<br><br>In Mathematics there is a schism between mathematical analysis &amp; algorithms (that emerges from geometry?) -&gt; two traditions: platonic (abstract mathematical expressions) vs processual (from life) histories..<br><br>&quot;How to frame AI? As an instrument of knowledge. A knowledge machine, not different from the telescope and microscope. To access scales of being that we normally do not access, to be able to see the society, to analyze data, and so on&quot;<br><br>Algorithm &#x2F; Heuristic &gt; one is fully deterministic and gaurantees an optimum result (vs. heuristic -&gt; trial&#x2F;error based system).... we don&#x27;t have a science for ML yet, in terms of a theory.&nbsp;<br><br>&quot;Capital &#x2F; Capitalism is like a very spurious calculation &#x2F; finding spurious-heuristic solutions. AI and capital together have these dirty, messy, spurious models ... instrumental rationality never existed at the level of precision that the Frankfurt Schule implied.. &quot; &gt;&gt;&gt; Neural Network systems are incredible information compression systems...<br>There are different types of biases: social bias, classification bias, etc... but in the end capital... you want to save time and make the computation as quickly as possible to make money.<br><br>Schooling: CS still focuses on Turing-complaint algorithms &amp; static data structures&#x2F;state machines &gt; with inferential learning as a secondary body of skills related to statistics. &quot;These two informatic epistemes cannot co-exist. The inferential &amp; nature-inspired approaches put into question Turing-complaint informatics. They put into question everything: persistence, RAM, etc..&quot;<br><br>&quot;In 50s&#x2F;60s randomness was used as protest, today randomness is used to calibrate a neural net. There is a change in the aesthetic role of randomness.&quot;&nbsp;<br><br>Notion of &quot;the general intellect&quot;, from Marx ... only appears in English translations. This was part of The Machinery Discussion in England..<a href="https&#x3a;&#x2F;&#x2F;en&#x2e;wikipedia&#x2e;org&#x2F;wiki&#x2F;General&#x5f;intellect">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;General_intellect</a><br><br>&quot;The model is never really trained, it always need to be within an evaluation&#x2F;revision loop. The feedback is there and is part of the division of labor. They are constantly being fixed (extended into the global south through crowdsourcing platforms, etc) ...is necessary for a heuristic process as such.<br><br>&quot;The Enlightenment&quot; &gt; total disassociation, we create a mechanism for pre-emption that is predicated on its own system. &quot;The beauty of the Englightenment is that we never have to focus on the now ~ but we can use pre-emption methods and techniques of abstractions&quot; &#x2F; space &amp; time &gt; colonial conceptions (?) &gt; Denise Ferreira da Silva &#x2F; first people&#x27;s have time measured by cyclical systems &amp; generational projections...&nbsp;<br><br>Enlightenment problematics: establishing a reference point (Euclid) for enabling measurement and understanding as a deviation from that reference point. Spatial-Temporal (similarity&#x2F;distance&#x2F;example-based) AI systems carry this philosophy with them - enlightenment&#x2F;categorical traps that reduce&#x2F;exclude relational&#x2F;ecological thinking. Referencing: Fanon &quot;the performance of racism is an articulation of race as it is understood at that time&quot; ~ similar to data politics&#x2F;algorithmic discrimination. Fanon: &quot;there is an escape&quot; &gt; find the ceremony that worships the necessity of an other (e.g. Chakrabati - climate change is not a global problem, villages in SE Asia are not making a large impact with fossile fuels, it is a western capital-industrial problem that implicates &quot;others&quot; in the logic)<br>Jack Whitten, Apps for Obama (Black Abstraction Movement)&nbsp;<br><br>Gium(?): &quot;algorithms amplify and fortify existing categories&quot;<br><br><br><br>___________________________________________________________________________________<br>PART THREEE<br><ul class="indent"><li></ul>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (20min)&nbsp; collective discussion on the material;&nbsp;<br><ul class="indent"><li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ^^^ let&#x27;s collect a few discussion points:</li><li><ul class="indent"><li>(10min)</ul></li></ul>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; wrap-up &#x2F; reflection on performance &#x2F; performativity &#8212; share future aims of the project: sound &#x2F; voice integration; interface and publishing..<br><br><br>equipment for workshop: beamer with HDMI connector; loudspeakers; access to wi-fi and printer.<br><br>___________________________________________________________________________________<br><br>other refs:<br><br>&quot;The reversal of the relation between organ and function amounts to liberating use from every established teleology. The meaning of the verb <strong>chresthai</strong> here shows its pertinence: the living being does not make use of its body parts (Lucretius does not speak of organs) for some one predetermined function, but by entering into&nbsp; relation with them, it so to speak gropingly finds and invents their use. The body parts precede their use, and use precedes and creates their function. It is what is produced in the very act of exercise as a delight internal to the act, as if by gesticulating again and again the hand found in the end its pleasure and&nbsp; its &#8220;use,&#8221; the eyes by looking again and again fell in love with vision, the legs and thighs by bending rhythmically invented walking.&quot;&nbsp;<br>&#8212; Giorgio Agamben, The Use of Bodies pp. 51&nbsp;<br><br>&quot;The body is an arrangement in spacetime, a patterning, a process; the mind is a process of the body, an organ, doing what organs do: organize. Order, pattern, connect... an immensely flexible technology, or life strategy, which if used with skill and resourcefulness presents each of us with that most fascinating of all serials, The Story of My Life.&quot; &#8212; Ursula K. Le Guin (Dancing at the Edge of the World: Thoughts on Words, Women, Places)&nbsp;<br><br>_____________________________ email from: <strong>Michaela B&#252;sse:&nbsp;</strong><br><br>&quot;The workshop will be attended by post-graduate students&#x2F;researchers interested in topics evolving around AI (...) You might want to talk about the background of the piece and your collaboration, questions that arise from the performance, exercises based on your performance or just a discussion. (...) We don&#8217;t expect you to fill these 2h with frontal presentation but engage the participants in your thinking and practicing. Beyond that, the workshop is meant to give everyone involved a change to get to know each other, learn about common research interests and extend the conversation over the course of the conference, so it&#8217;s less informal and hopefully a lot of fun.&quot; Academy of Art and Design FHNW&#x2F; Institute of Experimental Design and Media Cultures &#x2F; ixdm.ch &#x2F; ecam.ch<br><br>Preliminary workshop structure<br>Wednesday 19.06.<br>13:30 - 14:30 Welcome<br>14:00 - 16:00 Input Workshop 1 (HfG Karlsruhe, tbc)<br>Break<br>16:30 - 18:30 Input Workshop 2 (Christina Cochior, tbc)<br>18:30 - 20:30 Dinner<br>21:00 Performance Jonathan Reus&#x2F;Joana Chicau<br><br>Thursday 20.06.<br>10:00 - 12:00 Input Workshop 3 (Jonathan&#x2F;Joana)<br>12:00 - 13:00 Wrap up<br>13:00 - 14:00 Lunch Break<br>14:00 Beginning of conference<br><br>-----<br>Programme (tbc)<br>14:00 Official welcome (Claudia Mareis, Sabine Himmelsbach)<br>14:15&#8211;14:30 Introduction to the conference (Shintaro Miyazaki)<br>14:30-15:15 Speaker 1 Antonia Majaca<br>15:15-16:00 Speaker 2 Anna Ridler<br>16:00-16:30 coffee break<br>16:30-17:15 Speaker 3 Christine Meinders&nbsp;<br>17:15-18:30 Opportunity to visit exhibition<br>19:00 Keynote 1: Tobias Rees (tbc)&nbsp;<br>20:00 Dinner in Food Lab<br><br>Fri 21.6<br>09:00 Coffee<br>09:30-10:15 Speaker 4* Johannes Bruder + Maya Ganesh<br>10:15-11:00 Speaker 5 Christina Cochior&nbsp;<br>11:00-12:00 Keynote 2: Matteo Pasquinelli<br>12:00-13:30 Lunch time<br>13:30-14:15 Speaker 6 Ursula Damm<br>14:15-15:00 Speaker 7* Ramon Amaro (tbc)<br>15:00-15:30 coffee break<br>16:00-17:00 Keynote 3: Nora Khan<br>17:00-17:10 short wrap up, End of symposium<br>
</body>
</html>
